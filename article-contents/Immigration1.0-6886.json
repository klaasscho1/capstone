{"title": "Aspen Technology Inc Investor Day - Final", "body": "\nCorporate Participants\n\n* Antonio Pietri\n\nAspen Technology - President and CEO\n\n* Josh Fredberg\n\nAspen Technology - SVP of Products and Marketing\n\n* Suresh Sundaram\n\nAspen Technology - SVP of Products and Market Strategy\n\n* Karl Johnsen\n\nAspen Technology - SVP of Finance, CFO\n\n* Denis Westphalen\n\nNexen\n\nPresentation\n\nANTONIO PIETRI, PRESIDENT AND CEO, ASPEN TECHNOLOGY: All right. Good afternoon and welcome to \nAspen Technology's 2016 Investor Day. We're hosting the event here at our global headquarters in Bedford, \nMassachusetts. I also want to welcome those of you that are joining us on the NASDAQ website. I'm Antonio Pietri, \nthe president and CEO of Aspen Technology. Before we begin with our presentations today I would like to take a \ncouple of minutes to introduce the members of the Aspen Tech Board of Directors who are joining us today.\n\nThey are Bob Whelan, our Chairman of the Board, Chair of the Nominating and Corporate Governance Committee \nand member of the Audit and Compensation Committees. Don Casey, Chair of the Compensation Committee, Gary \nHaroian, Chair of the Audit Committee, Joan McArdle, member of the Audit Committee, Simon Orebi Gann, \nmember of the Compensation Committee and all independent Board members are also members of the Nominating \nand Corporate Governance Committee.\n\nSo let me now review the agenda for today and as I review the agenda I will also introduce members of the Aspen \nTechnology executive team that will be making presentations today.\n\n\nI will start with a company overview and a discussion around our strategy, that will take us probably until 2:00 p.m. \ntoday. Don't get worried.\n\nThen we'll talk about value creation on product strategy. Josh Fredberg, our senior vice-president of Products and \nMarketing will start the discussion.\n\nJosh joined us from ANSYS about 18 months ago. He was the CMO at ANSYS. He will introduce Suresh Sundaram \nwho is our SVP of Products and Market Strategy. After that we will have -- in between we'll have a 30-minute break \nsometime around 2:45. I'd better not confuse my times.\n\nAnd then as Suresh will come after that, we'll probably go until 4:00 or so once the market closes, then Karl \nJohnsen our SVP of Finance and CFO will come on and talk dual financial review and give FY '17 preliminary \nguidance. And then we'll have a Q and A session at the end. So that's the agenda for the next four hours or so. And \nlet's get started here.\n\nBut first of all Safe Harbor statement regarding our disclosures today and I'll leave them up there for a second so \nthat everyone reads it. And we also have a disclaimer regarding future product development or any discussion \naround future deliverables regarding our products, and the non-commitment to the claims or disclosures that we will \nmake.\n\nSo let's talk about Aspen Tech and what we consider to be our business trends. So the company will be 35 years \nold this August. Over that time our products and solutions have become mission-critical for our customers, and that \nis because they create tremendous value for these customers and you'll see examples of that throughout the \nafternoon today.\n\nThat value creation has led to the establishment of a world-class customer base, the Who's Who of the oil, \nchemicals and E&C industries which has created for us a market leadership position that we have in the industry \ntoday and the multi-billion opportunity that we feel is ahead of us as well.\n\nThis is all supported by our revenue model which is now a subscription revenue model, having completed a \ntransition last year that subscription revenue model is supported by long-term contracts normally on average of five \nto six years in length. And then this discipline that run execution in the company supports best in class profitability \nand tremendous cash flow generation, and then our focus on capital deployment to enhance shareholder value, \nwhether that's for M&A, shared buybacks or R&D spend. And you'll hear some more about that later in the \npresentation.\n\nSo these are what we consider the basic strengths of the company, both from a products standpoint but also a \nbusiness standpoint.\n\nSo talking about our industries we are concentrated into three industries and more than 90% of our business \nresides in these three industries, energy, engineering and construction, and chemicals. These are about $10 trillion \nindustries in a global economy close to $80 trillion or about 12% of the global economy.\n\nThese industries are characterized by complex manufacturing processes. When you head of a project like the \nSadara project in Saudi Arabia, JV -- between Saudi Aramco and Dow, a $20 billion investment, 26 downstream \nmanufacturing plants that will start producing about three million tons of product and will make Sadara a Fortune \n500 company, the day that all those units come in line immediately.\n\nSo there's a lot of complexity, a lot of technology, high capital costs, not only build to these assets, as I just said $20 \nbillion to build that petro-chemical complex, the largest petro-chemical complex every built in one place, by the way. \nHigh-volume production, if you think about it a typical refinery 200,000 barrels per day. If you buy crude oil at $50 a \nbarrel every day for 365 days, that's a $3.67 billion bill only to buy that crude oil.\n\nExxon Mobile has 5.3 million barrels of refining capacity, the largest refiner in the world. Their bill is $9.67 billion per \nyear at $50 a barrel. If you are able to save 1% of that bill every year that's $967 million in savings per year, that's \nwhat we do, that's what our products do and we do a lot more than that. So this is why Aspen Tech is relevant. In \n\n\n\naddition these are industries that require significant amount of technology and engineering to get through their day \nto day operations.\n\nThe dynamics for the industry, globalization, especially in the last 20 years, and I would say the last 10 years has \nbecome an incredibly globalized industry. Twenty years ago a lot of the supply chains were regional supply chains, \nthen the Middle East started coming online, Asia-Pacific and lately in the chemical side North America with shale \ngas and the chemicals investment. The supply chains not only have expanded but have gotten stretched around the \nglobe and are constantly changing.\n\nDow Chemicals in the mid-2000s made a decision to move all their chemical investment to the Middle East. Then in \n'09, 2010 shale gas came into the scene and they reversed their decision to move all their chemical investment \nback to the US because the US became the second lowest cost producer for chemicals but the logistics of \nproducing in the US versus in the Middle East made it much more attractive.\n\nSo the supply chains are constantly changing. Market volatility and I'm sure that will be a topic of questions today. \nOil prices going from $100 a barrel to $27 in January and now somewhere around $45, $50, creates tremendous \nchallenges in managing this business and planning for the future.\n\nChange in demographics, this is something that we hear from our customers all the time, the challenge that they're \nhaving with their demographics in their employee populations. They call it the two peaks demographics where \nthere's a peak of employees that are nearing retirement and they're going to take with them a lot of expertise and \nexperience about this industry. And the second peak is that new wave of college graduates that are being hired to \nreplace the ones that are retiring. And their lack of experience or expertise in the industries, but a different \nexpectation of not only software but in general what a job is these days.\n\nSafety and environmental regulations and certainly I probably don't have to elaborate on that but a few weeks ago \nthe explosion in Mexico of a petro-chemical plant, a joint venture PEMEX and Mexican cost the lives of about 27, 28 \npeople, probably hundreds of millions of dollars in costs. Environmental regulations, and we all know about climate \nchange, so it is only getting harder for these companies to operate in an environment where regulations are only \ngetting stricter and tighter and operate profitably.\n\nAnd of course the focus on operational excellence, but it's not only operational excellence it's capital topics \nexcellence as well, is supply chain excellence and its organizational excellence and due to the demographics. What \ndo they do to make sure that that knowledge and expertise that is going to be retiring is going to be transferred back \nto this new population of employees that are joining their companies.\n\nSo there's a lot going on in these industries, and the combination of the industry characteristics and the industry \ndynamics is what our products love. Our products love complexity because we optimize and every little bit that you \noptimize in an environment where there are huge volumes and huge investments translates into a lot of savings. \nThat's the example about ExxonMobil and under crude oil purchases a $1 billon if you can save 1% in the \npurchases of those crudes.\n\nSo those are the industry characteristics and industry dynamics. Of course the competitive dynamics are always \nchanging and more so in the last 12 months than perhaps in the previous 15 to 20 years. Certainly the upstream \nand midstream sectors are significantly challenged. These companies are managing their business for cash flow \ngeneration and to maintain a certain degree of profitability.\n\nRefining margins, the refining industry has certainly enjoyed a golden era of profitable operations, but at the same \ntime there's stresses in the system where you'll see Japanese refiners are going through a significant restructuring \nof their business because of the economic environment in Japan. You see European refiners and European \nrefineries are slowly closing down, but a lot of that capacity then opening up in the Middle East, opening up in Asia, \nsome places in Latin America and so on. So there's shift in dynamics and the different players are constantly \nadjusting to changes.\n\n\n\nUS refiners have been exporting products to Europe because it's been tremendously profitable for them over the \nlast two or three years to sell their products in Europe. Latin America is coming up short on supply, and now a lot of \nthe US refining production is going into Latin America because of a shortage of refining capacity over there.\n\nSafe operations and what entails which is a lot, and then the increasing environmental regulations. And on the \nengineering and construction side the dynamics at the moment are ones of just managing through the downturn, \nthat's what we're hearing from a lot of our customers. They want to understand what each other is doing and Aspen \nTech has the benefit of meeting with a lot of customers in a global basis. And when I meet with our customers they \nstart by asking me what are you seeing in the market? What is everyone else doing? They want to know if they're \nmissing something about what the market and what they're supposed to be doing.\n\nAt the same time some of these E&Cs developed a strategy prior to this downturn that either by chance or design, \npositioned them in a more positive manner for these downturns, so you have the E&Cs that are focused exclusively \non refining and chemicals and they are doing better than those that were focused exclusively in upstream.\n\nThe Japanese E&C had a strong focus on LNG and they were enjoying a nice run, even despite oil prices coming \ndown. Now LNG prices over the last few months have been coming down and they are now seeing some stress.\n\nKorean E&Cs were very focused on the Middle East and they are seeing a lot less investment. At the same time \nsome of them spent a lot of time in Iran and see Iran as a big opportunity for them in the next few years because of \nthe build-out that would have to take place in that country. As a matter of business they all feel for the most part \nthey need to get better at estimating what it takes to deliver a project to their customers.\n\nOne of the issues they are facing is a lot of project cost overruns and therefore when we engage with these \ncustomers, one of the points of discussion all the time is our capital cost estimation product and solution. A lot of \nthese customers are building departments and hiring more people just around the use of our technology because it \ngives them a better way to better optimize the cost estimate for their customers. ConocoPhillips using our capital \ncost estimation software was able to improve the cost estimation from plus or minus 40% to plus or minus 10% and \nthat represented millions of dollars for them, for example.\n\nAnd the one thing that we're seeing that is a common theme at the moment is a lot of these companies are looking \nfor areas where to focus to generate new revenues and brownfield existing assets, not about designing a new plant \nor building a new refinery, it's about how can we contribute to improving the operations of existing assets and what \nservices can they provide to their customers in that area. And this regard they are very interested in Aspen \nTechnology because they know that a lot of that improvement in operational performance comes from our products \nand we have discussions with some of these E&Cs about leveraging our technologies in their focus on brownfield.\n\nAnd then chemicals, certainly over the last 12 and 18 months is the area that I would argue is the best performing \narea. Certainly not only have their feedstock cost come down but the global economy continues to grow, their \ndemand continues to grow and therefore their margins have improved. Dow Chemicals in this last quarter a record-\never profitability in their operations and that's because of the margins they're enjoying. I was in Asia last week and \ntalking to a Korean chemical producer and they said exactly the same thing, record profitability and that's again the \nmargin that they're enjoying at the moment.\n\nThere's new capacity, that capacity that was being built in Asia and the Middle East over the last three, four, five \nyears and it's now coming online. The Sadara Project is starting up right now and it will take them another 12 \nmonths because it's such a large project. But also then you have the North American chemicals capacity that is \nbeing built now that will start coming into production in '17, '18, '19. So there is a wave of new assets coming online \nthat will also benefit ourselves.\n\nThe supply chains, not only are they getting extended but they're getting reconfigured. Although the cost of building \nthese assets have come down in the last 18 months which was one of the big issues in the energy industry. It's still \nvery expensive to build these assets because of their complexity, and that's again an area they focus on.\n\n\n\nAnd then the other major trend that we see happening is that a lot of the biggest chemical producers are moving up \nthe food chain from bulk chemicals production into specialty chemicals. So the whole activism around Dow \nChemicals and DuPont had a lot to do with that, divesting from low-margin bulk chemical assets into higher margins \nspecialty chemicals.\n\nThere's other companies in Europe, DSM, Bayer-- even BASF that are migrating towards specialty chemicals away \nfrom bulk chemicals, the Middle East, China and other countries have become the bulk chemical producers in the \nworld.\n\nHaving said that because of the US and shale gas and now being the second lowest cost producer in the world \nthere's a lot of new bulk chemical capacity being built in the United States at the moment. So a lot is going on these \nindustries and it's always been the case, but it feels like it just gets accelerated every year.\n\nI talked to most of you about this all the time when we made the business environment while we're seeing as far as \nour business and I will try to encapsulate what normally takes 30 minutes to discuss in a few minutes here.\n\nBut on the energy side of course the CAPEX cuts, it's estimated at over a period of four or five years, that's about \n$500 billion in CAPEX cuts announced and that will have a significant impact on the ability to ramp up oil production \nin the future. It's estimated that there's been about 325,000 lay-offs between the energy and E&C industries and \nthat's certainly has an impact on the human capital that will exist in the industry as the industry recovers.\n\nCertainly independent upstream, midstream companies are under financial duress or stress. We see that, we see \nthat in the contracts that are coming up for renewal. Some NOCs are under significant stress and I would \ncharacterize those as NOCs that represent a significant percentage of their home country's financial revenues. And \nwe've talked about some of those NOCs in our earnings call as well.\n\nDownstream refining continues to be profitable. We're entering the driving season in the US, Europe and other \nplaces, and margins should improve over the summertime. Gasoline prices are increasing in the gas stations and \nthat's margin expansion for refiners.\n\nIntegrated oil companies are leveraging their refining assets to maintain some degree of profitability, cash-flow \ngeneration and their ability to pay for those dividends. And that's certainly proving the strategy that some of these \ncompanies have had of creating integrated assets, both upstream refining and petrochemicals as well.\n\nYou've seen it, probably you've purchased your own big SUV, but in the United States over the last 12 to 18 months \nthere's been a resurgence of big SUV purchases that's driving gasoline demand and increasing that consumption \nwhich is a healthy thing for the refining industry in general, and operational excellence is a priority. Every customer \nthat we talk to has an operational excellence initiative, and we fit nicely into part of that initiative.\n\nOn the E&C side, well, the CAPEX cuts by these oil companies are having significant impact on the E&C \ncompanies. And like I said some of them are doing better than others. The layoffs are certainly -- they are actually \npart of the layoffs and we see that in less usage of our software in some of these companies. What we've learned is \nthat these companies manage to a two-year backlog and they do that by throttling their headcount.\n\nSome E&Cs are doing better than others because of how they were positioned before this downturn. The ones that \nare facing refining and chemical they are actually well and buying more entitlement from Aspen Tech, their focus is \non cost estimation and project execution.\n\nThere's cancellations and reductions that we see in spend, but at the same time through the usage logs that we get \nfrom these customers we also see that there is some Tier 1 companies that are still experiencing denials of service, \nmeaning they don't have enough token for the amount of usage that they need of our software. And of course that \nintensity of usage have come down in the last 12 months but we still see those denials of service, but very cautious, \na lot of caution by these customers around spending.\n\n\n\nWhen will the trough of the market be for E&Cs and I get asked that question. Well, my simple answer to that is \nwhen the oil companies start spending more. And when that happens then you'll see a lag and then the E&Cs will \nstart hiring more people.\n\nOn the chemical side it's mostly a lot of positive dynamics. Again, I've mentioned most of these positive GDP direct \ndemand increase, the feedstock advantage in the US from shale gas and investment that's coming into the US, the \nshift towards specialty chemicals, operational excellence, and we're seeing a lot of M&A activity in the chemical \nspace. We normally see that as a benefit when we see M&A activity because it gives us an opportunity to engage \nthose customers in a discussion around our contracts, and normally there's a cross-pollination that takes place \nwhen two companies come together that leads to greater usage of our software.\n\nSo these are the dynamics that we normally see and we're seeing in this business environment. We've given you \nthis information in the past, perhaps a little bit more granular, but about 38%, 40% of our business is energy and it's \nplayed on a 60, 30, 10 basis. About 31% is E&C and 26% chemicals, the other 5% is a list of these industries, \npharmaceuticals, metals and mining, power and utilities and so on. And that's how our business is distributed. It \ntakes a lot to change those splits because it's against a revenue base at the beginning of the year of about $420 \nmillion. So a single year of performance doesn't necessarily change these numbers a whole lot.\n\nSo why do customers choose Aspen Tech? I think a lot has to do with the deep domain knowledge and expertise \nthat we have in hydrocarbon processes. Of course the large and measurable return on investment.\n\nWe solve complex optimization problems and that's what they deal with every day, the breadth of our solutions. And \nI would say if we want to be known as something to these customers is as domain experts, not only because of the \nsoftware but the knowledge and expertise that's embedded in the software, but also our understanding of the \nindustry's best practices, the value that we create, the bench-marking that we can do of one company against their \npeers. So there's a lot that we can bring to the table and over the 35 years it's not only about our products but also \nhow we can present those products to them as well.\n\nThese are some examples of how we create value and there's thousands of these examples, this is just six of them. \nAnd in Petrofac, a stabilizer column in an oil field was receiving crude oil that was heavier than the design called for, \nthere were limitations to this. And through the use of HYSYS an analysis was done to determine whether the \nbottleneck in the stabilizer column was going to be resolved by increasing the temperature or reducing the \npressure. It turned out that it was through the reduction in pressure, and that saved this customer about $4.8 \nmillion.\n\nAnd you see those examples, LG Chem, they wanted to double the capacity of a solvent recovery unit in a \npetrochemical plant, but also reduce the energy consumption, through the use of our Aspen Plus and Aspen \ndesign rating tool, not only did it double the capacity but they say 40% of energy from the initial basis, [momentive] \nthrough the use of our plant scale and technology in 70 plants around the world.\n\nAnd standardizing the technology integrated to SAP were able to improve their customer service by 35%, but also \nincrease their on-time order fulfillment through their customers by 12%. So it's not only value creation but also \nproductivity. Improvement, the same thing at Samsung, Reliance and many of these other customers. Last year \nduring the Optimize Conference we talked about Aspen Tech and our products creating about $50 billion per year \nof value. We've gone back and looked at that number and we're ever more convinced that it's at least $50 billion of \nvalue that gets created from the use of our technologies on a yearly basis.\n\nIf you go back to the example I gave you about ExxonMobil, they're heavy users of our technology, 5.3 million \nbarrels of refining capacity a day, saving 1% on their crude oil purchases is a $1 billion alone, and that's just from \nour planning tool. So if you all up all these together we can come up with that number and more.\n\nAnd then finally these are two solution suites, our product suites, our engineering suite that represents 70% of our \nsoftware revenue. And our manufacturer and supply chain suite that represent about 30% of our software revenue. \nAnd this is information that we've also given you in the past.\n\n\n\nSo let's move on to strategy. And we introduced our strategy last year also during Optimize 2015 right at the \nbeginning of my presentation in the plenary session. Our strategy is one of asset optimization. We believe that \nasset optimization is the future of optimization. It will transcend the functional silos that you find in a plant design \noperations and maintenance. We believe that in the future customers will be focusing in the entire asset life cycle \nand how to optimize the asset from an asset life cycle standpoint.\n\nWhen you hear E&Cs talk about brownfield and focusing on brownfield operations it's really about the maintenance \nof those assets. How to optimize the maintenance of those assets we believe that by evolving our scope of \nexecution from design and operations into maintenance will become that much more relevant for owner operators. It \nwill be a holistic approach and we'll build on the 30 years of expertise, 30, 35 years of expertise that we've created.\n\nAnd if you look at Aspen Tech there has been two distinct phases to the company. You could argue that the project \nin MIT was also a phase. The company started as a modeling and simulation company of one product. Eventually it \nmade an acquisition that moved it into dynamic simulation from a steady state. It has two products. But then in the \nmid '90s it began to consolidate the advanced automation space and between 1994 and 2002 it made 23 \nacquisitions. That moved the company from modeling and simulation into process optimization it's what we are \ntoday.\n\nI would argue that the process optimization phase is taking longer than you would have imagined because of the \nturnaround that the company went through in the mid-2000s, 2005 to 2010 or so.\n\nThe opportunity exists for us to evolve the company into asset optimization and continue to leverage the huge \nopportunity that still exists for us in the design and operation space into the maintenance. It will expand the TAM, it \nwill expand the opportunity for us in refining and chemical, and any other asset that we may decide to go and focus \non.\n\nSo we consider this to be a significant opportunity going forward. We are particularly excited about this opportunity. \nCertainly if you view Aspen Tech, we're the global leaders and the design operations of these assets, it would \nrequire us to extend ourselves into the maintenance space.\n\nThe thing about the maintenance space is that it's not a space that it stands alone by itself, it's a maintenance \nspace that is tightly integrated with operations where Aspen Technology is today and with the design of these \nassets. Our view is that going forward when these assets are designed we can make sure that in those designs not \nonly we're taking into account the capital costs or the capital effusion of building those plants and how they're going \nto be optimized from an operational standpoint but how we can also optimize them from a maintenance standpoint \ntaking into account the reliability, maintainability and operability of those assets into the design.\n\nWe can also look at how these assets are planned and how the design is done to take into account the full range of \npotential operations of that plant in different business environments but also in different economic environments as \nwell.\n\nAnd then from an operations and maintenance standpoint this is an area with few companies - and it's a very \nfragmented space. You see a lot of small software companies doing pieces of the work in the maintenance space. \nWe believe the combination of optimizing operations with the maintenance, looking at the root cause analysis, \nlooking at the reliability of those assets and how they can be operated in a way that extends the lifespan of \nequipment in those assets will lead to more optimum decisions in the future.\n\nCertainly the goal is to anticipate asset life cycle, extend the life cycle of those assets, make those assets more \nprofitable across business cycles, not just one scenario and optimize that with operations, with objective two, \nmaximize the return on capital, minimize the risk, mitigate risk from the operation of these assets while sustaining \ncompetitive advantage over their full asset life cycle.\n\nWe are already working on this. And I will give you a few more details here.\n\n\n\nNow what does that mean for Aspen Tech? Well, we want to expand the depth of what we do. Today we're very \nfocused on what's processed in these assets. We want to be focused on not only what's processed but on the \nequipment that is processing that feedstock, that crude oil or that ethylene to turn it to polymers. What are the \nissues that are impacting the equipment that lead to the gradation of operations? So it's not only about how do we \nbetter fractionate the crude oil, but how do we mitigate the issues that are impacting the equipment?\n\nWe want to expand the scope of our solutions and we want to go not only would we want to be focused on the unit \nand the process and that's been our 35 years so far, but we want to expand that scope to the full plant, to the site. \nSo over the last five years we've made acquisitions that have actually started to push us into the boundaries of \nthese assets. We've made acquisitions in the safety area. We made acquisitions in the environmental area. We \nbought a dock and scheduling solution that moved us into the off-sites of these plants.\n\nSo there's a much bigger opportunity when you focus on the asset of the site of the plant as opposed to just the \nprocess unit. And then we want to expand our activities. As I just mentioned we want to go from the design, the \nplan, and operate into the design, plan, operate and maintain. So we'll bring with us our history and the success \nthat we have and in a way this is the way to create more runway, TAM expansion and continue to grow the \ncompany going forward.\n\nIf you think about what we are to date on the design space, if you think of any customer when someone says, well, \nwe are going to find a way to better manufacture this product, or we are going to create a new product because a \ncustomer is asking for a different type of products specification they start with our products.\n\nOur products they are using in the R&D department but they are also used to come up with those designs that don't \nexist today, that is sort of the conceptualization of these products or designs, but when then we move into the basic \nengineering, once those designs are approved and then we worked in laying out how that plant is going to look, the \ndifferent pieces of equipment, the sizing of that equipment, the interiors of the different equipment, but also how \nmuch is going to cost to build that plant or that refinery.\n\nOnce that's all completed then that moves into the detail engineering. We do some detail engineering work for Shell \nand tube mechanical heat exchangers, but most of the detail engineering work is in passed onto to companies like \nAviva, Hexagon, Intergraph, Bentley, they do the detail engineering for this plant.\n\nOnce these plants are built then Aspen Tech comes around and those models that we built during the \nconceptualization and basic engineering are used online. They are used to do studies, the bottlenecking studies; \nthey are used to do analysis on these assets to understand perhaps why a plant is not processes in as much as it \nwas designed to do to perhaps understand why the product qualities that were designed for plant are not being met.\n\nThose are all studies that are done when these plants are operating, to, again, optimize our operations and are \nusing the models that the engineering firms created when they designed these plants. So that's what we do in the \nasset design, the aspenONE engineering suite.\n\nIn the asset operations similarly, you may have a refiner with six or seven refineries. They decide they want to build \nanother refiner. Well, that starts with a study, the strategic planning study using our planning tool to identify what is \nthe best location for that plant, for that refinery or that chemical asset. What are going to be the feedstocks and \nwhat are going to be the products that it has to produce?\n\nAnd once that is decided, our tool, our multi-planning tool, multi-plant planning tool is used to determine the \noptimization, what refiners or what chemical plants it should produce for what market, and what products?\n\nOnce the plants are operating, well, the day to day planning is done with our planning tools, then once you create a \nplan you would create a schedule of how you're going to execute that planning and the refineries on the chemical \nplants that's done with our tools.\n\nAll the data that those plants are generating, or temperatures or pressures that's all being captured by our real time \nthat is a management software IP 21.\n\n\n\nIf it's a pharmaceutical company, well, they're using Aspen production Record Manager to track exactly what \nhappened to that product along the production process, FDA requirements for example. But also customers want to \nunderstand the material balance from a production accounting standpoint.\n\nBelieve it or not in some parts of the world stuff gets stolen before it gets to the end of a plant in the production \nprocess. So you want to do of what went in and what came out to see what are your losses and understand if you \nhave leakage in the plant. We do that as well.\n\nAnd eventually we have our control software, our optimization software that sits on top of this plant to optimize \noperation and make them produce what they have to produce as optimally as possible by consuming the least \namount of energy by processing as much as possible to produce what's required. That's our Aspen manufacturing \nsuite at a high level.\n\nWe're saying that we believe there's an opportunity to take all that, leverage our design and operations expertise, \nour products and solution, and move them and leveraging them into the maintenance space.\n\nWe've announced that we've been working on an Analytics solution because over 35 years we've become a \nplatform for our customers. A lot of the data, the models and the information that our customers have and used in \ntheir assets it's in our products.\n\nSo we believe we can leverage that know-how, that access to all that information to create a set of analytics that is \nnot only data analytics but the leverage is an empirical representation of those assets in our engineering models, \nand bringing the predictive capability of models with the analysis of that data to create predictive and prescriptive \nanalytics for our customers and you'll hear more about that from both Suresh and Josh later today.\n\nAnd once you do analytics you want to be able to understand well what are the equipment anomalies, what's \nimpacting that -- what are the issues with equipment and what's impacting that equipment, what is it that's \nhappening in the upstream of the process that's leading to these issues?\n\nDo a root cause analysis and understand how you can improve the reliability of those assets and this is what we \nbelieve we can do in asset maintenance by extending ourselves. It will require some organic development. It will \nrequire some acquisitions but it will leverage our entire suite of products and solutions that we have today. And \nwe're very excited about this.\n\nSo that's our strategy. In a way it's an evolution. It's not a drastic step change. It's leveraging what we have today \ninto the maintenance space and complementing that with some development and acquisitions that we are focused \non today.\n\nIt will leverage the same expertise and know-how we have about these assets as well. So let's talk about quickly \nhow we go about this. In the past you've seen this slide, the same headers. We've added one around that Aspen \nTech ecosystem. We believe as we try to grow the company we want to have other third-parties out there helping \nus drive more of our products into the market.\n\nBut let's talk about product innovation. And I will touch on it at a high level. I know both Josh and Suresh will do a \ndeep dive on this, but again our product innovation will continue to focus on what we do today. And the design and \noperations of this asset, and we'll extend ourselves into the maintenance space.\n\nWe want to make sure that our products are faster and easier to implement. Our customers are telling that and \nwe're focused on that area. We want to make sure that they are secure to be accessed anytime from anywhere and \nwe simplify the user experience and we believe that one way to do that is through automation of knowledge work \nthat is encapsulating the knowledge that it takes to use our product in the software so that that knowledge no longer \nrequires - it's a click of a button and that analysis is done.\n\nWe've talked about activation and you're going to hear about that as well. It's prescriptive analytics. We don't want \nour analytics solution to be a major project for our customers. We want it to be what I told the team to be, a slap-on \n\n\n\nanalytics. You install them, a little bit of configuration and you're on with analytics, and other areas where both Josh \nalso will elaborate.\n\nSo our focus is on product innovation, last week we announced the release of our V9 version and Suresh is going \nto go in detail into this. But two things to highlight specifically, our blow-down technology acquisition is now had \nbeen released in the release last week.\n\nWe are the only company, blow-down was the standard technology in the world for de-pressurization analysis. We \nbought the technology and we are now the only simulation and modeling company in the world that has this \ntechnology.\n\nSignificant differentiator and Sulsim, we bought the technology also from the company Sulsim. And it's now in our \nHYSYS product. It will allow our customers to model sulfur recovery units, predict sulfur emission and it was a gap \nthat we had in our modeling technology and now it's filled.\n\nBut there was also a lot of other innovation that was released in V9 and you'll hear more about that some more \nlater.\n\nI will talk a little bit about prescriptive analytics because this is something that we're very excited about. We're now \nin the beta phase of this development. The customers that are working with us are excited about what they are \nseeing. Some of them have already asked to take the software and start working with it in their own operations.\n\nSo like I said it's not only about data, it's about the ability to predict what's going to cause a problem and prescribe \nsolutions to avoid that problem going forward. It's about bringing models and data together which is a big \ndifferentiator from a lot of other companies in the market where they just talk about data.\n\nAnd there's a lot of companies out there that do not have the vertical industry expertise to give context to that data. \nWe believe that the key different for Aspen Tech in analytics and the use of models is also the vertical industry \ncontext that we can give that data to make it meaningful and create value.\n\nOur initial focus is on equipment and Josh will talk about the equipment that we are going to start to focus on, and \nthen the many other pieces of equipment in units. But we're focusing on equipment that are common around the \nworld that represents in some case hundreds of thousands of these pieces of equipment where if you do analytics \non each of them and you avoid the problems that they demonstrate can mean hundreds of thousands or millions of \ndollars in savings for our customers. And this is only through the combination of models and data.\n\nBut it's also more than that because in a way the vision that was originally laid out for Aspen Technology 25 years \nago by the founder of the company is coming about. By consolidating this space we ended up with our unique set of \nasset technologies.\n\nThe vision was that at some point you can bring all of these together to bear, to create huge value for our \ncustomers. So what I've already said about data which comes through our Info-Plus 21 product and models which \ncan HYSYS and Aspen Plus their solution will also eventually be able to leverage our advanced process control as \nsolution for example.\n\nIt will be able to leverage some of our new search and pattern recognition capabilities that we've developed in the \ncompany, some of the data that exist in our cost estimation tools and our planning tools. So it will start leveraging all \nthe solutions in the maintenance space to create huge value for our customers.\n\nSo we are incredibly excited. I think we're at the beginning of a new phase for the company and there's been \ntremendous work that's gone into this and you'll hear some more about it in a little while.\n\nSo penetrating the customer base this is a question that I get asked from a lot of you. Well, what does that mean? \nWell, as what I've normally said it's going deeper into with our customers, more users of the same product, and \nmore users using different products. But it's not only that it's providing the educational content so that these users \nunderstand the value that they can create.\n\n\n\nIt's also talking to them about and perhaps not necessarily the users but their managers and executives about \nbench-marking. How do they benchmark from a usage standpoint of our products versus other companies? And \nwe've done that with many customers.\n\nAnd the reaction is an unbelievable reaction when they see themselves bench-marked, again, to other customers \nand they start asking questions about, well, why is this customer using more technology than us? What's the \nreason?\n\nThey want to know why they are not where some other competitors are. We talked to them about best practices and \nover the last 18 months we have started to talk to them about, you know, where are they in the maturity model to \nachieve those best practices? And they get very interested when, you know, if you're talking about a scale of 1 to 4 \nand maybe they're at level 2, well, what's going to take to get to 4? How much more software usage and how much \nbetter do we need to get on the use of our technology?\n\nSo penetrating the customer base it takes many directions and approaches. One at the user level but also mid-level \nmanagers and executives and we're trying to just get more granular on how we're approaching these customers to \ngenerate more usage.\n\nInvesting in emerging markets, this has been one of our initiatives over the last few years. Certainly with the \nchanges in the oil landscape we've taken a step back. Now we do think China is still a tremendous opportunity and \nwe continue to invest in China today.\n\nLatin America certainly is a region that is facing a lot of challenges at the moment, is a natural resources-based \neconomy down there for the most part. And those are the challenges that they are having, but we continue to \nexecute in Latin America.\n\nThe Middle East will account and is accounting already for almost 25% of the refining capacity in the world, almost \n20%, 25% of the chemicals capacity in the world, and we'll continue to invest in that region.\n\nRussia perhaps has been one of the most exciting surprises in this downturn because despite everything that is \nimpacting Russia they've continued to invest every quarter on technology. I've said it before from a technology \nadoptions standpoint they felt to me like they were sort of in the late '90s, but into the late '90s in the US and they \ncontinue to adopt a lot more technology from Aspen Tech.\n\nAnd the SMB in this downturn certainly was the first one impacted. It delivered positive growth last quarter. And \nwe've taken this opportunity to look at how we've optimized that organization but we're committed very much to \ncontinue to drive our sales through SMBs.\n\nFrom a digital channel standpoint what I'll say though it's a few hundred companies that represent 80% of our \nrevenue but it's hundreds of thousands of users, and we want to get to them regularly with content, educational \ncontent, training, and the only way to do that is digitally. We cannot do that face to face.\n\nSo we've been working on putting in place a platform to deliver content to these users on a regular basis and we're \nwell down that path. We're already starting to see the results but it's one of the areas that we continue to invest and \nwill invest in FY '17.\n\nIt requires multiple channels of engagement not only at webinars but also mobile communities, and all sorts of stuff, \nbut we're very excited about the opportunity that this will represent for us.\n\nPursuing acquisitions, [well], it's an effective way to drive shareholder value and we've done five since 2012. We \ncontinue to press the flesh to see what we can do in that area. We have a pipeline of acquisitions, most of them \ntuck-ins. And, you know, we're hopeful that some of them will happen in the future.\n\nI get the question, well, are there any medium or large-sized acquisitions? You know, when we think of acquisitions \nwe think of them in the context of can they support our long-term profitability target and our growth aspirations.\n\n\n\nAnd when you put that filter on acquisitions you end up with a very few of them if you're looking at medium or large \nsize. Nonetheless I would say in the category of bigger than small -- and in the small and medium range there's \nprobably one or two acquisitions out there. And, you know, we look at those companies but our announcement of \nour buyback plan for FY '17 should signal to you that we don't think it's something that is that imminent in the future. \nBut we're continuously evaluating opportunities.\n\nExpanding the total addressable market and this a metric that we started to give two years ago and you're going to \nget an update here. We do believe we have a unique TAM and that we can calculate the TAM and I will give you \nfirst of all the methodology that we used for those of you that were not around in the last couple of years.\n\nOur TAM was originally focused on our top 350 accounts. Last year I mentioned we noticed a gap in our TAM \ncalculation and that our TAM was based on estimating that the TAM for the top 350 accounts and then extrapolating \nit to the other 20% of our business which we assumed was SMB.\n\nAs we got into it last year we noticed that there was a group of accounts in this emerging regions that were not yet \nin our top 350 but they were not SMB. These are big customers in the Middle East, in Latin America, in Russia, in \nChina and other places, until we decided to go back this year and look at those accounts.\n\nAnd we added about 150 accounts to our TAM calculation. That means that we've developed a new TAM number \nfor an additional 150 accounts in our calculation. The TAM is estimated based on both the white space and the \ninstalled base, by site and by product for each account.\n\nSo it's based on existing customers at the time we do the TAM and the existing products and functionality at the \ntime we do the TAM. It's not about the future. It's about what we have today in front of us.\n\nWe do that for every site in every account. We estimate the white space and the installed base. We assign the \nnumber of tokens to those products for both the installed and the white space. We designate average dollar per \ntoken for those tokens.\n\nWe roll that number up for each account. And then we do it for all the accounts and that gives us a TAM number on \na TLCV basis and an annual spend basis. And then we extrapolate it for the other 15% to 20% of the accounts that \nare SMB for which we do not do a manual estimate for the TAM.\n\nSo that's the methodology and the basis. The TAM is finished, the TAM calculation because also to give you a \nsense is completed by December of every year. The numbers are rolled up and calculated in the first three months \nof the year and then normally May and June, we give them to you.\n\nSo this is a number that reflects our TAM as of December 2015 and the functionality that existed at that point. So, \nwe released V9 last week. The V9 functionality that was released still not in the TAM. The blow down and sourcing \nwhite space, for example, is not in the TAM.\n\nSome of the impact from the downturn is in the TAM because some of these E&Cs had laid off employees, \ntherefore there were less process engineers in some of these companies and the TAM is adjusted down in that \ncase as well. So we account for the dynamics in the industry as well.\n\nSo, what drives TAM expansion? Well, industry growth, the organic industry growth and these growth projections \nare from IHS and Platt and ARC, I'm sorry. Their own projections for the expectations of the growth of this industry \nin 2016, 1% for energy, 3% to 4% for chemicals. No growth for engineering.\n\nIt also takes into account escalations, so we have price increases of 2% to 3% every year. The TAM expands from \nescalation as well. It expands through product innovations, adaptive process control, acid gas modeling, \nvisualization and analytics, activation. When we release analytics that will be part of it and also acquisitions, which I \njust mentioned.\n\n\n\nSo, these are all the things that expand the TAM on a regular basis, and really when we talk about industry growth, \nit's probably new refineries or new chemical plants or E&Cs, if they've hired more engineers or if they laid off more \nengineers.\n\nSo what are the numbers? These are the two numbers for '14 and '15. This is a 2016 number, about $12.1 billion in \nTAM. The installed on a TLCV basis back in December was about $2.1 billion.\n\nWe assign an equal number of tokens to the competitors' products and also an equal value to their tokens. To \nestimate that number is an approximation. We do know that they charge less than we do, so we're generous with \nthe pricing, but certainly they don't sell on a token basis. So, it's just an approximation.\n\nSo our TAM -- the total TAM for 2016 is $12.1 billion. The available, the white space TAM is $7.9 billion on a TLCV \nbasis. So what expands that TAM or what expanded that TAM in 2016 and new products and functionality that was \nreleased before December of last year, between January and December.\n\nYou are looking at version 8.8 in May of last year and version 8.9 in November, I believe, and the functionality that \nwas released in those versions. You are looking at additional sites that we added when -- well, we now -- the one \nthing we've done as well is we've gone out and gotten better data, market data about each of these customers.\n\nWe've bought some databases and now we know we are missing some sites in our top 350 accounts. And then we \nadded these additional 150 accounts to the TAM. So that is the detailed analysis for the TAM expansion that you \nsee.\n\nThe other thing that we've done this year, is we've converted the TAM number from TLCV to annual spend, \nbecause going forward, the metric is annual spend, so on an annual spend basis, this is the metric, is at $2.61 \nbillion in TAM on an annual spend basis. And the available TAM on an annual spend basis is about $1.77 billion as \nof December of this year.\n\nSo, this is the number for 2016 and again, a year from now we'll update it again. And this is the value of the \nfunctionality in an annual spend basis as well, just a conversion from the numbers that you saw earlier.\n\nSo in addition, we have five years business plans for every one of our major products. In a way, we know what \nwe're going to do with our products five years out, especially over the next two, three years.\n\nWe understand the business impact that the development work will involve. We understand the TAM creation from \nthose product roadmaps. So in a way, we have visibility as we release this functionality about how our TAM is going \nto expand over the next five years.\n\nAnd based on the reviews that took place in February and March of our business plans, we have a very good idea \nof how our TAM will continue to expand. This is just to give you a sense that it's not something that it's \nhappenstance. We have an internal goal of expanding this TAM every year by a certain percentage and that's \nbaked into our product plans and our product roadmap.\n\nSo here, coming to conclusion, talking about the Aspen Tech ecosystem and this is a new slide. We've had a \nchannels organization in place for many years now. The channels organization represents less than 5% of our \nbusiness. And we're going to be focused on cultivating third-party relationships to continue to drive more of our \nproducts and solutions into the market and expand our business outside of our core industries through third-parties.\n\nWe're going to be focused on establishing partnerships with industry players to drive Aspen Tech products into the \nmarket. There are some industrial companies that find themselves not able to compete with other industrial \ncompanies that compete with Aspen Tech. And they are interested in leveraging our products and solutions and \ninclude them in their solutions and take them to market. For example, there's also other consulting companies that \nare interested in creating business out of implementation of our solutions and be actively involved in promoting and \ndriving our solutions in the market.\n\n\n\nWe have an ecosystem of implementation service partners and actually it is a sizeable ecosystem. And we're going \nto be focusing on expanding that ecosystem as well, so that that capability to implement our solutions is more and \nmore for our customers.\n\nAnd then like I said, with analytics we believe there's an opportunity for Aspen Tech to become a platform for a lot \nof these E&C companies to leverage our solutions and products, to provide services to their customers in \nbrownfield operations. So, this is all part of the development of an ecosystem that we're focused on and will drive it \nforward as appropriate.\n\nSo, to close here, what are the areas in FY17 where we're planning incremental investment, considering that FY16 \nhas been a year of low growth, and particularly at this time of the calendar year, the business environment hasn't \nchanged that much.\n\nSo we'll continue to focus on research and development. Expanding the core functionality of our products. \nCertainly, we believe we need to invest in specialty chemicals and round out our solutions in that area so as to \nmake ourselves much more relevant for a lot of these chemical customers that are moving up the ladder into from \nbulk chemicals into specialty chemicals.\n\nWe're investing in analytics and what's going to be required to deliver an analytic solution and also an asset \nmaintenance solution and that, of course, is organic development, but also M&A. As part of our dealer marketing \nstrategy, we're putting in place a marketing platform, which is part of our information systems, but we're also \ncontinuing to upgrade our information systems going forward in order to scale and support the ability to scale the \ncompany in the future years.\n\nSo those are the areas of investment that we've identified for 2017. And in closing, I hope what's come across in my \npresentation is that despite this downturn, Aspen Tech has both the financial strength and the product and solution \nstrength and the strategy to continue to drive the company going forward.\n\nAnd eventually, again, our aspiration is to get back to being a double-digit grower in the future. We're working on \nthe things that we believe will position ourselves to achieve that status and maintain the discipline in our execution \naround profitability and how we return capital to shareholders.\n\nSo, with that, I conclude my presentation. And I want to introduce Josh Fredberg, who will take the next session. \nThank you.\n\nJOSH FREDBERG, SVP OF PRODUCTS AND MARKETING, ASPEN TECHNOLOGY: Thank you, Antonio. Good \nafternoon. My name is Josh Fredberg. I'm responsible for the products organization, so product strategy and \nproduct roadmap across all of our products. And I'm also responsible for our marketing organization.\n\nThis afternoon, we're going to do something a little bit different. We're going to talk about innovation at the next \nlevel of detail. We're going to start with a first chapter that talks about our products as of today, as of V9, which we \nreleased just a couple of weeks ago. And I hope what you take away from this presentation is how our customers \nactually use our products and the connectivity across our portfolio.\n\nWe really have more of a system than a loose collection of products. So I hope you have an appreciation from that -\n- of that as we walk through these stories and then finally, the value that's delivered to our customers.\n\nWe're going to take a break after that and then we're going to talk about the future. What are we going to do to \nsubstantiate this asset optimization strategy? So what is our roadmap? And give you a little bit more insight into the \nspecific investments that we're making to make this vision a reality.\n\nBut we're going to start with today. I'm going to introduce Suresh next. Suresh is part of my team. And he's going to \nwalk you through our portfolio today and then we'll have a break after that.\n\nSURESH SUNDARAM, SVP OF PRODUCTS AND MARKET STRATEGY, ASPEN TECHNOLOGY: Thank you, \nJosh. Can you all hear me back there? Excellent.\n\n\n\nSo, I'm going to talk about the aspenONE product suite. So there are three things that I want you to remember. The \nfirst is that in this next session, I'm going to do a deeper dive into our products as they are today.\n\nAnd I'm hoping to show you how the different elements of our engineering suite and our manufacturing and supply \nchain suite come together in an integrated manner to address customers' business challenges.\n\nThe second point is that we released version nine of our software last week, a week ago yesterday. And this \nversion has a number of new innovations in it. And they build upon a number of other innovations that we have \ndelivered in the preceding few years. So, I'm hoping to show you a preview or an insight into all of those new \ninnovations that we have delivered over the past few years.\n\nAnd the third point I want to remember is that there's a significant opportunity in front of us. There's opportunity for \nour customers to migrate from older versions of the technology to newer versions, so they can take advantage of all \nthe new innovations. And that also represent significant opportunity for Aspen Tech, both from the increased token \nconsumption that comes from the new innovations, but also because these new innovations can be used to solve a \nbroader range of problems. So those are the three things that I hope to bring out in this next session.\n\nSo, first, let's talk about what is the problem we're trying to solve? It's an optimization problem, right? We are trying \nto make sure that our customers are optimizing the allocation of their capital and their resources.\n\nIt's not a simple optimization of just profit. Instead, they are looking at multiple, sometimes competing objectives. \nThat we want to make sure that they are deploying the capital efficiently. They are being efficient in their use of \nenergy. We want to facilitate productivity and innovation. We want to maximize yields. And we want to make sure \nthat we design and operate these facilities such that they can be controlled, that they operate in a safe manner and \nwith the minimum possible impact on the environment.\n\nSo these are complex sort of challenges. And our customers are looking for someone like Aspen Tech who has a \ntechnology breadth and depth to address all of these challenges simultaneously. And we are the only company on \nthe planet that can do this.\n\nTo illustrate and show you what our technology can do, I'm going to tell you a story. And this story is going to focus \non a specific vertical, the energy vertical. And, in fact, I'm going to focus on the refining sub-vertical of energy. And \ntell you the story in terms of what happens in a refinery. What are the business challenges that our customers face? \nAnd how those business challenges can be addressed using our technology.\n\nThe same story could be told for other verticals, but I think you will get the idea if I just pick one. In this presentation \nI'm going to show you several product screenshots. I don't think anybody here is a user of our technology.\n\nBut I thought you could at least get a feel for what the product looks like by looking at screen shots of the product. \nSo to start with, let's just talk a little bit about what is happening in the energy vertical, very specific to refining. And \nthis is picking up some of the points that Antonio already mentioned.\n\nSo the first is there's a lot more crudes available in the market, right? The graph on the right-hand side shows that \njust in the OPEC crude basket, the number of crudes that are available between 2004 and 2015, there's been a \nsignificant increase.\n\nThere's also, as you know, the U.S. ban on crude exports has been lifted, so there's even more crudes available in \nthe market, outside of the OPEC crude basket. So refiners are having to evaluate multiple crudes and make sure \nthat they are selecting the right crudes to process in their refineries. That represents an opportunity for Aspen \nTech.\n\nIt's not just that the number of crudes that are available are increasing, but the characteristic of the crudes are also \ndifferent. You've probably heard of light oil and heavy oil, you all have heard of sour and sweet. So the mix of crude \nis also different. So a simple change that a refinery can do when they are processing lighter crude instead of \nheavier crude is to increase the capacity of the equipment and that drives on average a 1.5% increase in capacity. \n\n\n\nBut if they are sophisticated enough to actually be able to process blended crudes, they can drive a lot more \ncapacity. And our technology allows them to do that.\n\nNumber three, as Antonio mentioned, refining companies have had operational excellence initiatives for a number \nof years. The graph on the right shows what Valero has been doing since 2008, where every year, they are \nmeasuring the performance of all of their refineries against very specific indices that they measure, such as \nmechanical availability, energy intensity and so on. And so, these guys are looking for optimization software \nbecause that is the way that they can improve the operational excellence of their units and their sites.\n\nAnd then finally, we're talking about the demographic challenge, especially in this downturn as companies are \nreducing workforce. A lot of senior, more experienced engineers are leaving the workforce. Newer, less \nexperienced engineers are coming into the workforce and, of course, there are two sets of challenges on \nopportunities this creates. One is the opportunity to embed knowledge and package them in such a way that you \ncan deliver them to the end-user, so that they don't have to be an expert.\n\nAnd the second is the ability to create new user experiences, because the younger audience, of course, demands a \ndifferent user experience in what their older peers might have. So these four strategies, kind of, inform our product \nstrategy throughout. And as you will see, we have included many of these elements in our products.\n\nSo Antonio mentioned about our two product suites the engineering product suite and the manufacturing supply \nchain product suite, so I go through my story, I will be picking up elements from each of our product suites and \nshowing how they are used to satisfy and solve business problems.\n\nSo imagine that we are talking about a refinery. So the refinery business challenges can be grouped into four major \nbusiness processes; plan and schedule, engineering, process control and manufacturing execution.\n\nAnd I'm going to come back to this graph on a periodic basis. So in the beginning, what's happening is a refinery is \ntrying to decide what crudes of all the crudes that are available in the market, they should purchase and process in \ntheir refinery. Once they have made their decision, how should they plan their refinery. And once they have their \nplan, what should the schedule look like to operationalize the plan. So that's the planning and scheduling function.\n\nThe engineering function comes in because now they're saying, while the planner has picked a certain set of crudes \nto process, what impact does it have on my refinery? Is my refinery going to be able to process it? Should I make \nany changes to my refinery to do it better? How much is it going to cost? Is it going to be safe? What's the \nenvironmental impact going to be?\n\nSo all of these fall into domain of engineering. The process control folks come in because they'll say, OK, the \nplanner and the scheduler say this is what they want to run in the refinery. How do I control my refinery so that it \nactually does what they want it to do. More than that, can I push my refinery to its limits to get the most I can out of \nall the equipment that I have in the refinery?\n\nAnd then finally, manufacturing execution is about making sure that the refinery is doing what it's supposed to. It's \nabout monitoring the refinery, monitoring all the different equipment. It's checking to see whether the equipment is \nas effective as you think it ought to be and getting other insights about the refinery that you might feed back to your \nengineering division, your planning division, or your control division and say these are some things that you could \ndo better.\n\nSo let's start with our first one, planning and scheduling. So here we're trying to figure out first what crudes to \nselect. And as I said before, there's a lot more crudes available in the market and there's a lot of different types of \ncrude available in the market.\n\nSo in order to make the decision of what crudes to purchase, you have to know how the crude is actually going to \nperform. And in order to do that, you have to know the characteristic of the crude and that is described using what is \ncalled an Assay.\n\n\n\nSo the Assay, which is the colored vertical bars there, basically tell you for each crude, what are the different \nfractions that you can expect such as gasoline and diesel, jet fuel and so on. So it gives you an idea of what you will \nbe able to make from that crude when you process it through a refinery.\n\nAspen Tech has a technology called Aspen Assay Manager, which has the data or the assays for over 700 \ndifferent crudes that are available in the market today, but more importantly we have actually a proprietary \nalgorithm, which is based on molecular modeling that can predict the characteristic of a new crude that be new to \nrefinery and new in the market.\n\nSo when a planner is trying to decide what crudes to process, typically, they are looking at anywhere from 20 to 50 \nto a 100, maybe even 200 different crudes. And they have to run multiple scenarios against the crude because they \nhave to decide, well, what if certain pieces of equipment is not available?\n\nWhat if the prices change? What if the product demand changes because of seasonality? So they run multiple \nscenarios. So the planner is typically running an optimization problem where they are looking at multiple crudes and \nmultiple scenarios. And for each one of those combinations, they are trying to solve an optimization problem.\n\nIt's a very complex problem and we have a technology called Aspen PIMS or Advanced Optimizer. That is the best \nthat's out there in the market that's guaranteed to get you as close to the global optimal solution as possible.\n\nNow, you can imagine that running these cases is actually quite compute-intensive, right? Just in a simple case of \n20 crudes and 30 scenarios, that's 600 different cases. They can take hours to run. In the extreme cases of 100 \nplus crudes and multiple scenarios, you can take days.\n\nSo what we have been able to do is to enable our technology to run our multi-core processors and high \nperformance computing machines and several of our advance customers and actually running many cases, 24/7, \nso that they are always picking the best crude that's available in the market. And now remember, as Antonio said, \nmillions of dollars can be made or lost in making decisions on which crude to purchase. And our technology is very \ngood at doing that.\n\nNow, once you have selected what crudes you are going to purchase, you have to do crude scheduling and you \nhave to derive your operating plan for your refinery. And when deriving the operating plan, you have to take into \naccount actual constraints in the equipment, what equipment is available today or next week. Planners are typically \nlooking out a few weeks to maybe a couple of months out.\n\nSo they need to take into account what might happen in the refinery that will actually going to impact their plan. So \nour technology takes into account actual real constraints of things like pricing, equipment availability and so on, so \nthey can derive a plan that's going to be most feasible to actually execute in real life.\n\nNow, the way the planning model works is the planning model makes an assumption of how the refinery is actually \ngoing to perform. So they have these empirical models that encapsulate the performance of different units in the \nrefinery and that's what they use to do the optimization.\n\nNow, you can imagine that as a refinery is operating, changes occur, equipment degradation happens, the crude \nchanges, there's changes in the weather that might impact the performance of the model. So the model that is \nbeing used by the planner is not in sync with what's actually happening in the plant. Now, they can update the \nmodel by doing studies in the plant and collecting the data and refitting the model to the plant, but that's expensive.\n\nAnd here, we have a significant advantage because we have a product called Aspen HYSYS, which is a leader in \nsimulation in the energy space that actually has first-principle models for all the refinery units in a plant. So using \nthe actual first-principles model they can use that to update the planning model, so no need for doing plan studies \nand experiments and data gathering and so on. And what we have done in the last version that was announced last \nweek is we have automated the update of the planning model with the regular simulation models. So very quickly, \nthe plan can be updated and utilized by the planner.\n\n\n\nSo once the planner has determined the operating plan for the refinery, as I said, they are looking at a few weeks to \nmaybe a couple of months ahead of time. The scheduler has to come in and figure out how they're going to \nschedule the plant, right?\n\nSo the scheduler, imagine, is someone who comes in every morning. They have to see what happened in the \nprevious day, especially what happened the previous night. Was there a tanker delivery that was supposed to \nhappen that didn't happen? Was there a shipment that was supposed to happen that didn't happen? So they have \nto do the best they can with the schedule. So while the planner might say, I want to run the plan which is shown by \nthe blue line, the scheduler is not able to achieve the blue line, right?\n\nSo they are -- they try to achieve as close possible, which is actually the black line. The scheduler is scheduling out \none or two days. The operator is the one who is in the front line, actually, trying to make the schedule work. The \noperator has to deal with real time situations, so there may be an alert that they have to go and investigate them. \nMaybe a pump shutdown that they may have to do. So the actual is actually even different than what the scheduler \nintended.\n\nSo we have technology that allows you to see the plan versus the schedule versus the actual. And this gives them \ninsight to go figure out what they need to change the close the gap between these three.\n\nAnd finally, it's not enough that you looked at all their different crudes and you looked at what was available and \nyou've selected what needs to be purchased. You have to make sure the crude is actually available.\n\nSo when you're scheduling your refinery, you need to make sure that the crude that you thought you were going to \nrun is going to be available when you need it. A lot of crude is still delivered through ships, so we have capability in \nour scheduling product; dock scheduling, which is an acquisition that we made that takes into account dock \navailability, tanker capacity and so on. So the refinery scheduler can take the full refinery and the dock scheduling \ninto consideration when they are doing collaborative scheduling.\n\nSo the opportunity here is significant. So we have computed the value that we have created for our customers. And \nour estimate is that we generate about $6.8 billion in customer profit every year. About up to $20 million a year in \nhigher quality operational planning and tens of millions of dollars in optimal crude selection. If you look at the Aspen \nTech opportunity though, out of the about 700 or so refineries that are out there, only 440 of them use our baseline \nplanning product which is PIMS.\n\nAnd out of those are only a 115 are using the advanced optimization product there that I mentioned before. And \nonly 240 of the 700 sites use Aspen Petroleum Scheduler. So we have significant opportunity to both up-sell our \nPIMS customers and the PIMS-AO but also cross-sell between our PIMS customers and our scheduling customers.\n\nWe've also learned from analysis of our usage logs that PIMS users that start using the advanced optimization \nproduct, increase usage by about 20%, of course, PIMS-AO costs about two and a half times more tokens than \nPIMS, so the greater value that the customer gets also translates to value for us in terms of higher token \nconsumption.\n\nI want to give an example of a customer that has embraced our technology in this space and how they started with \nabout 100 or so tokens back in 2010, when they converted to the aspenONE license. And you can see that over the \npast six years, they have been on a steady path of buying more and more tokens related to our petroleum \nscheduling product, our PIMS product, PIMS-AO product and there's another acronym there, MBO, which is a blend \noptimization product, which I didn't talk about, but is used for handling crude blends.\n\nI'm next going to show you a video of a customer who uses PIMS-AO for crude selection. It's one of our Korean \ncustomers and because the audio is not exactly clear, there's subtitles as well, so hopefully you'll be able to follow \nit.\n\n[Video]\n\n\n\nUNIDENTIFIED SPEAKER: And that depends on market situation. Every time we have to consider the best \nfeedstock in our plant and market situation. After introduced AO, PIMS-AO it dramatically decreased the time.\n\nWe do the main case study and find some different choice and it make really good decision.\n\n[Video Ends]\n\nSURESH SUNDARAM: Okay. That was a short clip. The next area we'll look at is engineering. And again, the \nproblem here that we're trying to solve is how is my refinery going to do with this new crude the planner has \ndecided to purchase. How much is it going to cost me? Is it going to be safe? What's the environmental impact? \nAnd so on.\n\nSo the first thing is that our planning software and our engineering software are integrated and the basis of \nintegration is the Assay. So the same Assay technology that is used to characterize the crudes that is used in the \nplanning software is also used in our engineering software. And so that makes it very easy for these two packages \nto talk to each other.\n\nSo what is the first problem they are looking to solve? Refineries are a complex thing, right? There are many pieces \nof equipment. There's complex interactions, there is recycles.\n\nAnd what the process engineer wants to do is to say, if we process this type of crude into my refinery, what is going \nto happen? And, of course, here we have Aspen HYSYS, which we believe is a gold standard for process \nsimulation in the energy space.\n\nAspen HYSYS together with the petroleum refining layered product and the full suite of refinery reactor models that \nwe have, allows the process engineer to build a detailed model of individual equipment units, but also a full scale \nmodel of the entire refinery. And that's what allows them to get a quick understanding of what impact is a crude \ngoing to have at my refinery.\n\nBut it doesn't stop there. As I said before, it's not only about simulating the process in the refinery and trying to \nmaximize profit. It's also about trying to understand what is my best utilization of energy? What is going to happen \nwith my equipment? So what we have done is we have taken many other complex technologies for economics, for \nenergy analysis, for equipment design and packaged them up and presented them to the user in a very simple \ndashboard panel right in the simulator.\n\nSo going back to what I said before about the change in demographics, so the user only has to worry about the \nbottom line impact of the decisions that they make. The very complex algorithms and IP that has gone in the \ncalculation of these results is actually hidden and that is an example of automating knowledge work.\n\nAnd with this kind of environment, it's not just a simulation environment, but a unified engineering environment that \nallows them to do everything related to a process from within the simulation tool.\n\nSo one of the things that they may be interested in looking at, specific pieces of equipment and the distillation \ncolumn is a critical piece of equipment in a refinery. And if there's operational problems in the distillation column \ntoday, what happens is there's, kind of, a dance that needs to happen between the operator and the equipment \nvendor where they have to try and get the data on what's the equipment internals and the equipment characteristics \nand try and figure out why is my column not performing as they're supposed to.\n\nWhat we have done in our new version that came out last week is we have enabled this hydraulics capability within \nour distillation columns, right within the software, so the process engineer can see that where I am operating, which \nis a red circle is outside of the feasible operating range that's shown by the shaded area within the two lines there.\n\nSo very quickly, they can understand here is where my column's feasible operating region is. Here is where it's \nactually operating and so these are the changes that I need to make in order to get my operation back within the \nfeasible range.\n\n\n\nAnother issue that the process engineer deals with is environmental compliance risk. Now, you know that there's \nmany crudes out there that are called heavy crudes. A heavy crude is a crude that's high in sulfur content. And \nsulfur is bad news both in terms of corrosivity on the equipment and also, it's not good for the environment.\n\nSo we have capabilities, a rigorous, again, going back to our roots of being able to mathematically model complex \nphenomenon, a rigorous rate-based distillation capability that allows a process engineer to specifically model what's \ngoing to happen with the sulfur and the acid that sulfur creates.\n\nYou can imagine that sulfur in the presence of water creates sulfuric acid, which is acid, it's not good for our \nequipment. So they can model what's going to happen and then figure out ways in which to remove the acid gas \nfrom the unit.\n\nAnd we also talked about the acquisition of Sulsim. It's not enough to take the sulfur out of the units. You can't just \nrelease it into the atmosphere because it's a hazard. So what companies do is they have a sulfur recovery process, \nwhere they recover the sulfur and the recovered sulfur is actually used in fertilizer or it's actually even used to make \nsulfuric acid, which is used downstream.\n\nSo with the integration of Sulsim into the Aspen HYSYS, now our user can do the end-to-end modeling of the acid \ngas removal, the sulfur recovery and the tail gas, which is then recycled back into the process.\n\nMoving on into safety. Another acquisition that we had was PSVPlus a couple of years ago, which allows a process \nengineer to make sure that the pressure relief system that they have designed is adequate and it can handle all the \ndifferent pressure relief scenarios that they might encounter in the operation of the process.\n\nAdditionally, all their different vents that come out of the refinery, the vent streams can be collected up and sent into \nanother simulator we have, which is a flare system simulator that allows you to make sure that your flare system is \ndesigned properly and you don't have unnecessary flaring of your gases from your refinery.\n\nAnd finally, to talk about blowdown Let me just explain what blowdown is. In many of these refineries, you have high \npressure vessels and high pressure pipelines. And sometimes you have to depressurize the system, either because \nof maintenance or because you are responding to an event like a fire or an emission event.\n\nWhen you depressurize a high pressure system, the liquids inside the system cool down and what that means is \nthat the walls of the vessel cool down. And if it cools down too much, those walls can crack and then you have a big \nproblem on your hands.\n\nSo what these companies do is they use a very expensive material of construction for all these walls, which is very \nexpensive. What Blowdown does is it allows you to simulate what's going to happen in a depressurization situation.\n\nIt tells you where the lower temperature is going to happen and where your vessels won't actually crack, so you \nonly pick the expensive material of construction for those vessels. So that's the Blowdown product. Again, it's now \nintegrated right into a simulator, so the process engineer can conduct depressurization strategies as a matter of \ncourse.\n\nAnd then lastly, all this is great, but we want to know how much is it going to cost. And we have, of course, the \nmarket leading product, Aspen capital cost estimator. The same capital cost estimator algorithms can be used in a \nconceptual phase what Antonio called as conceptualization to get preliminary and relative cost of alternatives, also \nin the detailed phase when you're actually thinking about building the plant and you want detailed cost estimates of \nall your different pieces of equipment and ancillary equipment. So it's the one economic model that's used \nthroughout the lifecycle.\n\nSo the value that we have created, we have estimated be about $5 billion annually for just our energy customers \nand that comes from increased production, about 3% to 8%. Increased plant profit, about $10 million to a $100 \nmillion per plant. And specifically, also by reducing capital and energy intensity by 10% to 20%. Thinking about the \nAspen Tech opportunity, we estimate that for engineering software, we have about 30,000 simulation users in \n\n\n\nengineering, but only 4% of them are using what we would call all the capabilities of the unified engineering \nenvironment.\n\nSo we see a big opportunity in expanding the scope of the process engineers to move from pure simulation to \nactually unified engineering. And, of course, as they use that additional capabilities, it consumes a lot more tokens.\n\nWe also see the significant possibility for us in getting new users in capital cost estimation. I'm thinking about what's \nhappening in the E&C market and the E&C companies wanting to get much better at bidding and estimating. It's an \nopportunity for us in cost estimation.\n\nWe see huge interest in our safety products. So we see a lot of potential to get new users in several of our new \ntechnologies that we have added over the past few years. And finally, we also see growth in many of our emerging \nmarkets, where they are just now getting on the technology adoption curve.\n\nAnother example of a customer, it's an APAC based energy company. As you can see that, again, this company \nhas embraced our technology and from the conversion to the aspenONE license back in 2011, they have steadily \nincreased the number of tokens and it just comes from adopting more pieces of the engineering portfolio and then \njust getting more users and getting the users to use more and more.\n\nI have another customer video for you this time. It's Denis Westphalen from Nexen, a Canadian company.\n\n[Video]\n\nDENIS WESTPHALEN, NEXEN: Any new cost project costs a lot, especially when compared to other areas of the \nworld. And we have to be very smart when we design a new process, when we design a new facility and again too \nlike process simulation too helps us to very quickly compare different alternatives, compare different options and \ncome up with the best solution that will give us the best bang for the buck.\n\nIt's nice to sit on the HYSIS flow sheet and access so many different tools on the same starting point, to start a \nrigorous heat exchange evaluation, from that same user interface to start an economic evaluation. To start the \nenergy analysis. We now have to learn the new safety analysis that's very important to our operations because \nwhatever we do, we can talk about the cost. We can talk about operational cost, but in the end of the day, safety is \nthe most important topic. And we are very pleased that we can run those evaluations from the [highest] platform.\n\n[Video Ends]\n\nSURESH SUNDARAM: Okay. Now that we have done our planning and scheduling. And the engineering guys have \nsaid, \"Okay, we know how to run this crude in our refinery. And here are some better ways to do it. This is how \nwe're going to do it.\"\n\nIt now comes to the process control engineers are going to say, \"Okay, how are am I going to take the schedule \nthat the scheduler came up with and make sure that my plant can be controlled, so that it does what they want it to \ndo. And then secondly, how can I push my plan to its limit?\"\n\nSo here, again, we have a technology called Aspen DMC3, which is our adaptive process control technology, that \nis, kind of, the market leader in this space. And the first thing that needs to happen is that the scheduler, when they \ncome up with your daily schedule, is really coming up with a target that all the equipment units need to adhere to.\n\nAnd those targets can become set points in the control technology. And we have several customers that are \nactually already doing this, where they're taking the targets that are being set by the petroleum scheduling product \nand saying, \"Okay, these are now one with the set points in my process control software, Aspen DMC3.\"\n\nThe way advanced process control works is you can think of it like the thermostat in your home, right? The \nthermostat measures the temperature in your room and depending on whether the temperature is higher or lower, it \neither kicks on or kicks off the heater or the air conditioning unit.\n\n\n\nSo that's a very simple, what is called single-loop controller. The technology in process plants is model predictive \ncontrol. They are usually looking at multiple different variables and controlling multiple different things that can be \ncontrolled. So it's a very complex algorithm, which is again, encapsulated as a model, okay? So the guts of the \ncontrol technology is a model that basically predicts what the unit is going to do if there are certain changes in some \nof the variables that affect that unit.\n\nNow just like in the planning area, even here, as time goes on, the response of the equipment changes. The \nequipment degrades. The crude characteristics are different. The temperature is different. The weather is different, \nso that model is no longer accurate.\n\nSo the operator, instead of thinking that the model needs to be updated, basically feels, \"Okay, this controller \nstopped working,\" so they shut the controller off. That means they are losing millions of dollars in value.\n\nThe solution to that, traditionally, has been update that model, but in order to update that model, they would have \nhad to shut down the plant, conduct some, what they call step change studies and then update the model and then \nbring it all back online, which is very expensive.\n\nAnd what Aspen Tech did is we introduced adaptive process control. And it's, in the last 30 years in this space in \nprocess control technologies, the most exciting thing that's really happened and when we told our academic \nadvisory board that we have actually a product that can do adaptive process control, they were astounded, right?\n\nSo this technology is basically self-calibrating. As the controller is operating and as the process is running, it's a \nself-toning model because it detects minute changes in conditions in the variable and then measures how the \nequipment is responding and uses that data to keep the model constantly updated.\n\nSo the controller never has to go offline, significant value to customers. And what we have done new in our version \nthat we released last week is we introduced this new technology, which we are calling our DMC3 builder, which is a \nsingle interface that a new user can use to actually build and deploy new controllers. They could be linear \ncontrollers, non-linear controllers, all types of different controllers can be quickly built and deployed from one single \nuser interface.\n\nSo it's really our, again, an example of automating knowledge work. What might have required an export process \ncontrol engineer to be able to build and deploy a new controller, we are now putting it in the hands of non-expert \nusers and we have several examples of customers that have actually done this and achieve record production \nlevels in record amounts of time.\n\nSo with DMC3, we estimate that we generate about $2.9 billion in value, just to the energy customers on an annual \nbasis. That comes from the increased yields of about 1% to 2%, reduced energy intensity by at least 5% to 10%. \nAnd also increased throughput of 2% to 4%.\n\nAnd if you think of the Aspen Tech opportunity, there's about -- we estimate just over 4,000 installations of \nDMCplus, which is the previous generation control technology in the energy vertical, of which only about 400 or \n10% of them have upgraded to DMC3.\n\nSo there's an opportunity to upgrade the other 3,600 to DMC3. But the other thing is because we have made it so \neasy to deploy control technology, it's now worthwhile for our customers to deploy it on other units where previously \nit may have been too expensive to deploy because the value may not have been as high. Of course, DMC3 \nconsumes more tokens, in this case about three times as many tokens as DMCplus.\n\nHere's an example of a customer. A U.S.-based refining company that has embraced, actually across our portfolio \nin the manufacturing space. They keep purchasing our additional tokens. They started with about 350. They add \ntokens for APC, for planning and scheduling. For IP21, which is what I'm going to talk next, which is our data \nhistorian. And as you can see, they continue to purchase more and more tokens.\n\nI have a video here as well.\n\n\n\n[Video]\n\nUNIDENTIFIED SPEAKER: We're an ethylene plant, so one of the areas that the DMC controllers that we have on \nsite are very important is in the area of furnace optimization where we try to make sure we control the excess O2s \nto the appropriate efficient limits and really, the DMC technology is the thing that enables us to do that very \nconsistently.\n\nAlso, at the backend of the plant, it's important for us to get our product out to meet the customer specification, but \nwe don't want to over purify that product or else then we are giving away a lot of energy as well.\n\nSo when we expect an operator to control the process, without DMC technology, they do a great job, but they do \nrun significantly more conservatively, which is really giving away margin. Our experience is that you just can't push \nthe plant to its identified asset constraints in any other way, really.\n\n[Video Ends]\n\nSURESH SUNDARAM: Okay. The final piece of the puzzle is now my plant is running. I have my plan. I have my \nschedule. The control guys have implemented the control strategies. I want to make sure it's doing what it's \nsupposed to.\n\nThat's where our manufacturing execution technology comes in. And here, you're answering questions such as how \ndo I monitor my plant performance? How effective is my equipment? And what additional insights can I get about \nmy plant?\n\nSo here, really, the challenge is about monitoring what's happening in the plant in real time. And as I said before, \nit's a complex environment, but we have technology which is InfoPlus.21 or IP21, which is a real time data \nhistorian. And the visualization product called aspenONE Process Explorer that sits on top that allows an operator \nto have 24/7 view of what's going on in the plant. So they can make sure that the entire plant or very specific units \nare operating in the range that it's supposed to operate in.\n\nAnd if it goes out of range, it can provide alerts to the operator. And it can also provide a lot of contextual \ninformation as to what might be happening that could explain that alert. There's also six sigma technology \nembedded, statistical process control, so that the users can evaluate how their equipment unit is doing and how far \nit is deviating from the optimal operating point.\n\nIt's a web-based technology. It runs on HTML5, so it's browser independent. It actually sits on top of any data \nhistorian, not just ours. One of the things you can do with the Process Explorer is understand their overall \nequipment effectiveness. This is important because -- my apologies there, so they not only have to know, you know, \nyou can't assume that the equipment is available the entire time that that's there. Within the total time, there may \nbe some time where it's shut down because it's a planned shutdown, there may be other time that it's shutdown \nbecause it's an unplanned plant shutdown, so the operator can really dig deep into what's really happening with my \npiece of equipment? What is unplanned and start getting into root causes of why is there an unplanned downtime \nand start taking corrective action.\n\nWe are in significant release of this, actually in August of last year. And what we have is spanking new graphics, it's \ngot extremely fast search algorithms that can deal with years of data in a matter of milliseconds. And as I said \nbefore, it's a browser-independent technology that can be deployed very easily with a very low total cost of \nownership. And it can be deployed on top of any historian. So here is an example of the value.\n\nNow, you might say that the value ascribed to this just seems to be low, $250 million compared to the other \ntechnologies. That's because what happens is most of the value that gets created from the use of this technology \ngets addressed by solving the problem with another piece of technology, so the value gets ascribed to that, right?\n\nBut we still can drive up to 3% production increase and a million dollars saved for each unexpected event that we \ncan avoid. This is a technology that actually has the largest number of end users of all of our software, right, \nbecause it's an operator-used technology. It is used in operator stations and control rooms on a 24/7 basis.\n\n\n\nSo just in the energy vertical, we see about 40,000 users who are still using our previous generation of our \nsoftware, less than 10% of them use the new generation software, which is aspenONE Process Explorer.\n\nWe have certain analytics capabilities that we have introduced into the technology, less than 1% of the users are \nusing this base level analytics capabilities. And using that actually consumes six times more tokens. So, again, \nsignificant opportunity for Aspen Tech to up-sell.\n\nSo here's an example a customer that's just, again, embraced our manufacturing supply chain suite, they stard with \nabout 550 tokens or so and they keep adding tokens for IP21 which is a data historian production record manager \nwhich is one of the products in that family. And they continue to grow and add tokens.\n\nThe last video is actually not quite a video but it's a...\n\n[Video]\n\nUNIDENTIFIED SPEAKER: We're very confident that we can get more value out of our existing Trends and \nProcess graphics by bringing them together in the new aspenONE Process Explorer. aspenONE Process Explorer \nis fast and the HTML5-based architecture eliminates client-side installs reducing our Total Cost of Ownership. We \nplan for many of our users to start using it right away.\n\n[Video Ends]\n\nSURESH SUNDARAM: Okay. I'm now coming to the close. I just have a couple of more slides here. So, what we \nhave tried to show on this slide is to show how our technology stacks up against two competitors; Honeywell and \nSchneider Electric. And what this table shows is I walked us through a workflow with business processes and within \nthis business process, what is the specific workflow item and showed you how our technology is used to address \nthe business challenge in each item of their workflow.\n\nAnd you can see that we have a pretty broad set of technologies to address all of these challenges. And if you look \nacross the other two columns without getting into the detail, you will see a lot of half filled or empty circles. So, \nreally, we are the only company on this planet that has the technology that can address all of the end-to-end issues \nthat are defining customer space. And the same story actually applies in all of the other verticals as well.\n\nSo, the question is how do we get this white space, right? So, the left hand side of this graph shows the white space \nin the energy vertical for our different product families. I don't show any numbers here but you can see the relative \nmagnitude of the white space.\n\nAnd the way to capture this white space is really either through up-selling or cross-selling. So, this white space is \nbased on our existing customers with our existing technology. We're not talking about going after new customers or \nbuilding new technology.\n\nSo, as an example, we have a lot of PIMS users who are still not using PIMS-AO so, a significant opportunity for us \nto up-sell and get all these PIMS customers to start using PIMS-AO. Same story in process control, we have a lot of \ncustomers using our DMC technology. Some of them are using an adaptive technology that we delivered as a \ncomponent but the package solution of DMC3 is still used by just a fraction of our customers, so significant \nopportunity to up-sell.\n\nAnd as you look at the top there, you can see that I added the blue circle for MES which has a very large user base \nbut there's very little overlap between our customers for our different pieces of technology. So, as I just fill this out, \nyou'll see that HYSYS, again, is used by a lot of our customers in the energy space but not all of them are using a \nplanning software or a control software or an MES software. So, we have significant opportunity to also capture this \nwhite space by cross-selling. So, we have initiatives in place to make sure that we are capturing all of our up-sell \nand cross-sell opportunities.\n\nOkay. So, that brings me to the end of my session here and I will turn it over to Antonio.\n\n\n\nANTONIO PIETRI: Yes. Thank you, Suresh. Great. Great job. Before we break, and it's a 30-minute break so until \nabout 3:25, I want to introduce one more member of my executive team and that is Bill Griffin. Bill, if you could \nstand up, please.\n\nBill is our executive vice president of field operations. He is me two and a half years ago. He's got global sales, \nglobal services training and customer support. He joined us about six months ago. He joins us from Autodesk and \nwe're very excited to have him. So, you'll have a chance to talk to him during the break as well so, 30-minute break. \nThank you.\n\nJOSH FREDBERG: Okay. We're going to get started again. Can everybody hear me okay?\n\nUNIDENTIFIED SPEAKER: Yes.\n\nUNIDENTIFIED SPEAKER: Yes.\n\nJOSH FREDBERG: So, we are -- we're really excited about the opportunity that we have. Suresh talked to you \nabout our portfolio today and if we didn't develop any technology, we have an exciting opportunity. But what we're \nplanning going forward really gets us excited to wake up out of bed and come in to work.\n\nI'm going to talk to you about futures so, this is a disclaimer. Anything that I say is giving you guidance about our \nplans but should not be interpreted as a commitment. Our plans do change over time.\n\nAntonio talked to you about our asset optimization vision and he talked about three dimensions of that vision, in \nasset design, in asset operations and in asset maintenance and asset maintenance really being a new addition to \nour strategy. He showed you also this framework. I'm going to spend time using this framework to really flesh out \nhow are we pursuing our strategy for asset optimization.\n\nAntonio talked a lot about the demographics and that there is a retiring population that has a lot of knowhow. A lot \nof how we're investing in features and functions is building out what we see are future practices and baking them \ninto the software.\n\nAnd I'm going to talk about of the specifics. We've organized them into six specific themes all around automation of \nknowledge work, not just the way companies work today but the way we think companies will want to work in the \nfuture.\n\nAnd then on the bottom of this chart, you see architecture. There are some architecture investments, investments in \ncore technology that allow our software to be implemented faster and easier and to lower the cost of ownership \nmaking it accessible anywhere and secure. And then finally, the user experience.\n\nI'm going to use this chart to kind of flesh out our strategy and we'll come back to this chapter by chapter. We're \ngoing to start with the architecture. So, let's talk about the user experience. What have we done already? Well, \nwe've invested quite a bit already.\n\nWe've invested in a consistent look and feel in our technology, all the engineering applications have the same style, \nthe same experience so that you know how to use one module, you know how to use another. We've done the \nsame thing for our enterprise software.\n\nWe've integrated our products so, activation all the examples that Suresh talked about, about how you can use our \nsoftware to estimate the cost, the cost to build new assets, the cost to maintain and operate those assets, energy \nconsumption, activations around equipment rating so being able to size and rate assets right in the same \nenvironment.\n\nBut we can go much further and I'm going to talk to you about that. And then finally we've invested a lot to make our \nproducts democratized. What I mean by democratized is that you shouldn't have to know a lot to use our software \nand get value.\n\n\n\nIf you have a PhD in chemical engineering or if you are supply chain expert, that's great. But we want to be able to \nmake new professionals, new to the workforce as productive as seasoned veterans. So, we've invested to make \nour software easy to use but also right through the software, you can get access to training and support.\n\nAll of that is available, we call it Aspen Exchange. But in the future, we can do much more. We're working on \nworkflows and best practices that take personas through multiple different product sets and in particular I'm going to \ntalk about in the planning and scheduling space we're re-architecting our products creating common data models so \nthat the experience right down the value chain from planning to scheduling to advance process control become \nseamless.\n\nWe're also investing in this new class of software that we talked about around analytics not to be confused with the \nkinds of visualization analytics in our MES suite, this is a whole brand new third family that we'll be rolling out. So, in \naddition to engineering, in addition to manufacturing and operations, this is a third family around Aspen Asset \nAnalytics and it leverages technology from our entire suite.\n\nWe're building in best practices. We spent a lot of time and energy especially over the last 18 months really \nunderstanding the way the leading companies work and taking their thought leaders and spending time with them \nto whiteboard the way they want to work and actually documenting that in terms of workflows, in terms of maturity \nmodels and we're spending more and more time with our customers actually thinking about the way they want to \nwork as opposed to just talking to them about features and functions.\n\nAnd all of this is manifesting itself into the software into all new role-based experiences so that given the role that \nyou're in it becomes natural and intuitive to use the software. You shouldn't need intensive training to get started \nand to drive value.\n\nLet's talk about security and access anywhere, anytime. Today, our portfolio is partially enabled on the web. Some \nof it is on the web. Some of it is traditional desktop. Some of it is traditional client server software.\n\nToday, we've got a lot of experience with virtualization. So, many of our customers use virtualization we test and \ntune our software for a variety of different virtualized environments. We've invested in security. So, we're leveraging \nall kinds of industry standards like ISA99.\n\nSecurity is incredibly important to our customers. Cyber security is an existential threat to these customers so, they \nwant to know that we are leading the way, that our software is as secure as any software in the planet because \nthere are safety issues, there are a variety of IP issues and it's at the heart of their business.\n\nAnd then finally, we've done a lot of work around private clouds with our customers. Many customers are using our \nsoftware already in their private clouds. What I mean by private clouds, this industry isn't ready at this point to go to \na SaaS public cloud environment. The security issues are too intense and the safety issues are too intense.\n\nBut they do want to have elastic capacity for compute power. They do want to be able to get high performance \ncomputing when they need it and to take advantage of the Azher and the Amazon's price points for hardware. So, \nthey want private clouds and they were already deploying our software in private clouds and we're working with \nthem and learning together as we build new commercial offerings around private clouds.\n\nBut in the future, we're standardizing towards a web infrastructure. We're building out HTML5 across our entire \nportfolio. This will give us optionality. It'll allow us to have the ability to take our technology into web and mobile \nenvironments. We'll see what happens with the cloud environments. We'll be ready when our customers are ready. \nThis gives us extensibility.\n\nWe're doing a lot of work around distributed computing. So, almost every module of our software has a high \nperformance computing opportunity. What do I mean by high performance computing? I mean leveraging not just a \nsingle core for a single job but leveraging dozens, hundreds or thousands of cores to be able to run thousands of \nscenarios or to take a really complex job and solve it very quickly.\n\n\n\nSo, high performance computing is central to our strategy. It's central to the value we need to deliver to our \ncustomers. They need answers quickly. They need to be able to make trading decisions often based in minutes. \nThey cannot afford days or weeks of compute time.\n\nSo, we're investing heavily, it's also a fantastic opportunity for us. We are now monetizing high performance \ncomputing. So, not only can we make money as more users use our software more often but we'll make money as \nthey use it more intensively. We will tokenize their use of high performance computing.\n\nThis is a brand new commercial opportunity and extremely exciting and extremely differentiated. We're leading the \nway in terms of our high performance computing scalability.\n\nMicro services and containers so, we're building out service environments where we can have services that are \nreused across our portfolio and we are getting very granular in those services so that there's lots of extensibility in \nour architecture. And we're doing it in a container environment.\n\nI don't know if you guys have read about dockers and containers. But this is an architecture strategy that we are \npursuing at this point. We believe that in the medium term, many customers are going to want to have a private \ncloud environment where they get to have elastic capacity for compute power but they want to control a little bit how \nthe software is deployed.\n\nThey have environments that require testing and validation. They don't yet want to have a public cloud environment \nwhere overnight they come in and a new piece of software has been installed but at the same time, they want to \nlower their cost of ownership.\n\nContainers can give us a way to give them a lower cost of ownership like you'd find in a SaaS model but give them \nmuch more control around the software that's deployed in their environment. And they want much more security.\n\nSo, we're building out the next layer of security where we're being very thoughtful with our customers about what \ninformation is being presented to which roles because that's an additional layer of security to make sure that the \ninformation is appropriate for that role.\n\nLet's talk about faster and easier implementation. So, we've already improved our download center. So, in our \ndownload center now customers can download their software and some still choose to get their software distributed \nfrom us, we send them USBs. More and more we're finding that customers will choose to use our download center.\n\nWe've got all kinds of utilities that we built up for customers. We call it a Silent Install so they can download the \nsoftware and customize scripts to be able to deploy the software in the way that they want to do it in their enterprise \nbut also build automation and lower their cost of ownership.\n\nFor product updates, we built an update center so that they can log on and the software is smart enough to know \nwhat updates are relevant to that enterprise. We've invested in central license managers so, customers now have \none central utility to manage their licenses and to look at their utilization of tokens and their usage.\n\nAnd then finally, we've built out templates that are industry-specific that allow them to rapidly deploy our software \nusing scripts that are very common for other customers like them. For example, we've built a polymers template \nand that's really speeded up and added a lot of value in the deployment.\n\nIn the future, we're going to cloud licensing. I don't mean cloud software right away, I mean cloud licensing. That \nmeans taking our license manager which has historically been inside their firewall and taking that to a public cloud. \nThere's a lot of good reason for that and there is very little security risk around the license manger so, that's \nsomething they're comfortable doing and there's a lot of value in doing it.\n\nSelf-service licensing, customers want to be able to move tokens from server to server or from site to site. We'll \ngive them the ability to understand their entitlement and self-service their utilization of our tokens.\n\n\n\nWe're investing in container-based deployment. I mentioned this already. So, this gives them the flexibility to adopt \nthe technology when they want to adopt the technology but rapidly lowers the cost of ownership because we can \nbuild it in a way that is operating system-agnostic. And we can deploy the technology very rapidly using containers.\n\nAnd then finally, rapid solution development, we will have one single environment for downloads and for updates in \none self-contained and easy-to-use environment. So, that's a little bit about our architecture.\n\nI want to spend much more time on how we're investing in our product features and functions to really support this \nasset optimization vision. Let's start with smart flowsheets. So, Suresh talked already about some of the challenges \nthat our customers face in evaluating new crudes.\n\nWhen a new crude becomes available, these customers need to think about the materials and corrosion for \nexample that are being used in their existing infrastructure. They need to think about the equipment in their plants \nand the configuration of their equipment, is it suitable for the new crudes that are emerging or available at good \nprice points.\n\nThey need to identify bottlenecks and improve the overall efficiency of their plants. What if our flowsheets, what if \nour engineering solutions were smart enough to give the user advice, to be able to ask the questions that a user \nmay not be knowledgeable not to even ask and guide them through some of the insights that a very seasoned \nengineer might actually understand after years of experience.\n\nSo, here we have, this is a HYSYS flowsheet. This is a configuration, an example of a configuration of a section of a \nplant. And we're introducing a new feedstock. Here, our flowsheet could give the user insight into which process \nflows might be problematic and which variables in particular.\n\nHere you can see one of the flows is highlighted in red and we see that there's a total asset number that's \nexceeding the limit. The flowsheets also are telling us that you know what, the distillation column could have a \nproblem given its current configuration. It would likely go into a flooded state.\n\nWe could go in and explore further and really understand where are we in terms of our operating envelope and \nwhat part of the distillation column is having the problem. It could then actually advise us about how to fix this \nproblem.\n\nIn this case, we had a prefractionator to fix the issue. And the model automatically updates and says everything is \nokay. That kind of workflow is really a form of artificial intelligence. It's actually thinking ahead to the kinds of \nproblems that really historically has only been able to been solved with an expert user.\n\nThat's an example. You could imagine how we could take this technology in a variety of different directions. I'm only \nshowing you a glimpse, right? A very simplified example might be your word processor. We take it for granted that \nit's checking grammar and spelling as you go. It's a very, very simplified example. Our authoring tools for simulation \ncould be doing the same thing.\n\nLet's talk about robust design optimization. So, Suresh talked about how customers want to be able to optimize \nacross many, many different constraints. They want to be able to think about the environmental concerns. They \nwant to be able to think about the profitability. They want to be able to think about the utilization. They want to be \nable to think about reliability and so on and so on. That's a very complex function that these customers are trying to \noptimize. It's not just one dimension.\n\nAnd they're trying to optimize it with many, many, many dimensions of uncertainty, right? So, they don't know what \nfeedstocks are going to be available in the future. And there are seasonal sources of variability. There are \noperational conditions that these customers will face.\n\nWhat if we could build out a next generation of software that allowed customers to build assets that are optimized \nnot just for one condition or a couple of known conditions but actually optimize across a broad range of uncertainty \nand actually having a robust design. That's a very complicated problem.\n\n\n\nHere we have examples where our software is already looking at activation so, we can understand the economics \nand the energy and size our equipment and we're adding in all kinds of new activations around safety and around \ncontrollability. We will continue to add more and more.\n\nBut what these customers really want to do is take this model and really start to understand the statistics involved in \nthe uncertainty. So, what we can do is we can build out a complex function that includes all the things that a \ncustomer would need to think about, all those different dimensions from profitability to environmental security and \nsafety and actually think about the inputs and the odds, the statistics, based on historical data, the actual probability \nof all those areas of uncertainty.\n\nAnd we can get a response service. So, we can actually understand not only a local optima but a global optima so \nthat they're building assets that are widely flexible for all the areas of uncertainty that they face. And, of course, that \nrequires complex math and it requires complex high performance computing to be able to run all those scenarios, \nsimplify it and give responses that are understood and actionable.\n\nLet's talk about connecting the lifecycle. So, today, our customers struggle with what they call the FEED. FEED is \nFront-End Engineering. So, there's a conceptual stage where they're thinking about the basic functions that a plant \nneeds to do and we can model that using HYSYS and Aspen Plus.\n\nBut between a conceptual model and a detailed model that has CAD geometries and all the details of what an asset \nor a plant looks like is Front-End Engineering where all the pieces of equipment and pipes are sized -- sized and \nspecified.\n\nAnd that process is very painful today. It's a process that requires all kinds of different constituents, estimators, \npeople who are doing detailed engineering, CAD people, project managers, mechanical engineers, civil engineers \nsometimes chemical engineers, they're often in different companies because engineering and construction forms \nare involved or consultants.\n\nSo, this is a problem that's a very challenging problem because it's globally distributed, multiple enterprises and \nthings are changing all the time. How do you keep track of the actual asset as it evolves from conceptual \nengineering stage to the FEED stage to detailed design in this multifaceted enterprise with multiple value chain \npartners?\n\nSo, we envision an environment where there's one single source of truth, one single source of truth where all the \ndifferent constituents can log in and they can see the asset definition through all the different stages of the lifecycle. \nThey can see how the asset is designed at their conceptual stage.\n\nThey can see the asset at the FEED stage and it can change and they can get real time alerts as to how it's \nchanged and everybody can sing from the same sheet of music. Further, we think we can do that very early in the \nprocess. Typically that FEED process does not begin until the conceptual stage ends.\n\nOur vision is that the FEED process can begin very early on in the conceptual process. We can build out a data \nsheet actually as we're building out our conceptual model and that data sheet can be kind of a record that keeps all \nthe different partners involved and in tune and we can automate the creation of this data sheet.\n\nWe can then also share it out so that there's one single place that all the different partners can log in and we've got \na real time dashboard of how the project is trending but most importantly we've got an effective change \nmanagement process. This is reducing millions of dollars of cost to what has been a very fragmented and \ninformation-siloed process. We can also save time because we're starting the process sooner front-loading some of \nthe most difficult challenges that we face.\n\nLet's talk about unified production optimization. Earlier, Suresh alluded to this challenge. Today, in the production \noptimization space, we've got a variety of different players. We have process engineers. We have traders. We have \nplanners. We have schedulers.\n\n\n\nWe have APC control engineers and plant managers. And the problem today is that each of these jobs requires \nslightly different information and slightly different timeframes. Planners are thinking about feedstocks and \nforecasting what production they need to run, what products are going to be in demand.\n\nSchedulers are thinking more in terms of weeks. And they're thinking about inventory levels and the physical \nconstraints in the -- in the factory. APC control engineers are -- their time is much more immediate.\n\nHow do we -- how do we ensure that all of these different functions are sharing information in real-time but also that \nthey're getting the information that they need so that better information and better decisions can be made?\n\nAnd this is a -- this is really a data model question. So we're investing heavily in data model. What if models were \nconsistent and some cases common for better optimization? So here we have an example.\n\nThis is a flow sheet that a planner might use. This is a representation of the plant in the way that a planner might \nthink. A scheduler looks at it not too differently. We could create a similar view but a role-specific view for a \nscheduler but linked to the same model of the asset.\n\nIt's about 80% the same. But by doing so you've reduced any redundancy of information entering, which causes \nmistakes and errors. And you can make sure that both planners and schedulers and later other functions are all \nworking from a common view of the asset. So it's critical.\n\nSo a planner needs to run hundreds sometimes or even thousands of scenarios thinking about crudes, which \ncrudes and production levels, and then later, the scheduler is thinking about inventory levels and production rates.\n\nAnd the problem that they face is that when the planner is planning his scenario, he doesn't actually know if it's \nfeasible. So he might optimize based on a schedule that isn't going to work. So that happens.\n\nWe have planners that generate a plan because it's been months in advance and he didn't have visibility into the \nschedule and then later it gets to the schedule, they have to redo it and they come up with a sub-optimal plan \nbecause it's feasible to the scheduler but it hasn't been optimized.\n\nOur vision is by building out a common data model, you could actually, as a planner, plan an optimal plan but that's \nalso a feasible plan. And as a scheduler, if something changes, you can optimize the plan with the constraints that \nyou have.\n\nSo brand new use cases to ensure that we're always optimal as a system and not just from a functional standpoint. \nBut it continues. If we look at a plan versus a schedule and then we compare to the actual, we find that there some \ndifferences.\n\nWe think we can narrow some of those differences by building out some of this common data -- data model \nbetween planners and schedulers but it could be that the asset itself is out of date because the planners didn't get \nan update from the engineering team that the asset itself has changed.\n\nSome piece of equipment has changed its configuration. So seeing that the plan, the schedule versus the actual is \nout of sync might be a good hint that the -- that the actual asset has changed and we can tie in directly into a \ncommon data model to the engineering domain.\n\nSo, now, we've got a common view of the asset from engineering, planning, and scheduling. And it extends all the \nway into APC. Suresh mentioned that some of our customers are already trying to be thoughtful about linking their \nschedule right into advance process control.\n\nWe think we can make that seamless so we can show that the way an individual asset, an individual unit is being \ncontrolled by advance process control is consistent with the schedule which is consistent with the plan and \ntherefore, the overall utility is optimized.\n\n\n\nSo this is all new. I mean we're the only company that can do this. These are very complex problems. Historically, \neach of these domains has been completely siloed and companies have workaround to try to bridge some of those \ngaps.\n\nThis is heart of what we mean by optimization and it's at the heart of where we're investing in terms of unified \noptimization. So now I'm going to talk to you about the maintenance domain, asset maintenance.\n\nAnd this is really new thinking and it'll be the first time we were or anyone's been exposed to some of this material. \nStart with maintenance. Historically, the process engineer is involved early on in the conceptual phase of a design.\n\nA maintenance engineer may be involved upfront but more often is tightly linked to operations. The maintenance \nengineer is really thinking about the maintenance schedules and making sure that the asset is being maintained.\n\nBut there's a great opportunity to actually bring these domains together early in the lifecycle and throughout the \nlifecycle of an asset. So what if we actually understood the historic maintenance challenges and the reliability of our \nasset when we were designing the asset.\n\nThat's what this is about. So specifically when an engineering today uses a process simulation tool like AspenPlus \nor HYSYS, the engineer is making assumptions about steady state.\n\nThey're assuming that any unit is up and they're optimizing their design based upon simplified assumptions about \nthe reliability of all those different pieces of equipment. But we know that plants go down.\n\nWe know that units go down. We know that there failures. What if we actually factored in the data about those \nfailure rates and actually use that data in a simulation model along with all the parts of our simulation model to be \nable to get a complete picture of not only the cost to build an asset, the cost to service an asset, the full lifecycle \ncost of that asset.\n\nThat would allow us to actually not only reduce the cost to the lifecycle but actually ensure that the asset's up at a \nmuch higher rate. That's the idea. We're actually now working on factoring in all the historic data into our simulation \nmodel so that we have a reliability view, a reliability model as part of our engineering model.\n\nThis improves the engineering design. It also improves the maintenance plans. So the maintenance engineers can \nget involved very early on in the lifecycle and actually improve their maintenance strategy based upon the very \nsame model.\n\nNow, let's talk about prescriptive analytics. We have here several different challenges in the different domains that \nwe sell into. We have process engineers that struggle to get real-time information about how an asset is actually \nperforming in the plant.\n\nAnd then influence the way is actually being operated. Typically, the engineer doesn't have a lot of levers to pull in \nterms of the operator decisions. You have an operator that is overloaded with information.\n\nThey sit in control rooms. They have all kinds of alarms that are going off, many of which are required from a \nregulatory standpoint. And it's information overload. They don't really, in many cases, they're unable to react to all \nthe information that they're presented.\n\nAnd you have a plant manager that's trying to bridge the gap between his process engineering team, which \nprobably has more insight into what's actually happening when problems arise, and the operator who needs to \nprocess all this information in real-time and actually make operating decisions.\n\nWhat if all the data were transformed so that we could make decisions as an operator before any problems arise, \nleveraging all the intelligence that are actually available to the process engineering in the engineering model?\n\n\n\nThat's what this is about. Antonio showed this slide earlier. We're building an analytic system that spends \ndescriptive analytics so that is what's happened, why did it happen, diagnostic analytics, predictive analytics, \nknowing before it actually happens.\n\nAnd then ultimately, prescriptive analytics. We think something's going to happen and we think this is what you \nshould do about it. We're building up a system for the operator that leverages models from the engineering team \nand big data analytics looking at the data coming out of the historian to be able to reach insights well before \nanything happens in the plant.\n\nWe think we're the only company that can do this. That can bring the models together with the data to be able to \npredict problems before they arise in the plant. And we think the only way to solve this problem is to bring models \nand data.\n\nThe challenges here are too complex to be able to just to take a pure data based approach. You can't know just by \nlooking at information that's in a historian what's actually happening in a chemical reaction. It's too complicated.\n\nYou need to be able to look at data. You need to be able to interpret the data through a model to be able to reach \nsomething that's actionable. Our strategy is to start at the unit. We're starting with columns, distillation columns and \nto build a complete solution for predictive, prescriptive analytics for columns.\n\nAnd then we'll move to other types of equipment like heat exchangers and other. Then we'll move to the plant and \nultimately to the enterprise. We think the opportunity is staggering. There are a 100,000 columns. So even before \nwe move to other kinds of equipment, there are a 100,000 columns today, distillation columns in the world. And \ndowntime costs about $10 million per column. And we think the vast majority of that downtime could be prevented \nwith a system like this. So tremendous amount of value that can be deployed here.\n\nHow are we going to do it? It starts with data conditioning. So we're lucky we have a historian that's part of our \nportfolio, IP21. So we've got a upgrade install base but half of the plants in chemicals are using our historian. But \nwe've designed it to sit on top of anybody's historian including Pi. So our strategy is to broadly deploy our analytic \nsolution anywhere there are distillation columns.\n\nWe then build out a first principal model that is an engineering model that is tuned to the actual configuration in the \nplant. We build out an empirical model also that is if you don't have a robust model based on first principles, we can \nbuild the model based on the data that's available.\n\nWe use that model to build a root cause model. That means that we understand all the data that's being collected \nabout that asset and how it relates to other pieces of information. So if something goes wrong, we know what the \nroot cause of that problem likely is. We use these underlying pieces of technology to build kind of an operating \nmodel. In this case, you see an operating model for column hydraulics, that's an operating envelope that is built on \nall the models that I described earlier.\n\nAnd we've built out pattern match capability so that when a problem arises, we can find out when it arose previously \nand ultimately put predictive alerts based not only on the model prediction but on looking for these kinds of patterns \nas they emerge together.\n\nWe take all this technology and we present it in a very simple dashboard to the user who is an operator. What \nmakes this technology special is it's designed to have very minimal services.\n\nWe think we can leverage a lot of the technology we've built out in APC around cells maintained and adaptive \ntechnology. The underpinnings here are exactly the same. So we could rapidly deploy these first principle models, \nthese empirical models, these root cause models, build out an operating model.\n\nBuild out pattern capabilities and ultimately build the dashboard. As Antonio said, slap on very little services and get \ncustomers up and running fast. And actually have it be self-maintained. So once this dashboard is up, it heals itself. \nIf something funny is going on in the data it understands and it heals, so it's self-contained. We think that this is hot \n\n\n\nstuff. We think that this is going to be incredibly valuable to customers, it's going to be easy to sell, it's going to be \neasy to deploy, and it's a major part of our strategy.\n\nThis is an example of what that dashboard might look like. So here we have six specific alerts. Some of these alerts \nmight be based on a model, some of these alerts might be based on a pattern match, and we can drill down as an \noperator to really understand.\n\nSo in this case we drill in and we see in this case one of those alerts was around a C2 splitter and it says it's going \nin to a flood state, here's the probability it's going to go into a flood state, and here's some prescriptive advice about \nwhat to do about it before it happens.\n\nWe can then as an operator very quickly say, \"When did this happen in the past, so that I can really understand is \nthis something that's been recurring and maybe actually in addition use this pattern to look forward if it ever \nhappens again, so I can build another alert because we've learned something.\"\n\nUltimately, all of this becomes very interesting when you combine it together. So the asset analytics is looking at \nmodels and patterns to find problems before they arise. As we learn about problems and fix them, we can use our \nengineering model to actually figure out how much of a challenge is it to fix this problem and given the production \nschedules, when would be the right time to actually fix it.\n\nUltimately, all of that gives rise to a better maintenance strategy. So we've learned and as we learn we're improving \nour maintenance strategy so that these problems are prevented and we don't even have to face alerts the next time \naround so this is a closed loop system.\n\nThis is a pretty exciting strategy and it's kind of a down payment on our overall asset optimization vision. This \ntechnology will become available this year. So this is not something that I'm talking about as very far out on the \nroadmap. This is a third product family that will become available with a new token pool, all new growth \nopportunities for the company will be launched later this year.\n\nOkay. So I'm going to end with a little video that we'll be using with our customers to kind of whet their appetite \nabout this new product family.\n\n[Video]\n\nUNIDENTIFIED AUDIENCE MEMBER: Manufacturers around the globe are losing billions of dollars a year due to \nunplanned downtime and off spec production. We've all heard about how big data and the internet of things is \ninfluencing general business practices, but in this industry the stakes are higher. Millions of dollars are lost in \ndowntime and a mistake can have disastrous environmental or safety consequences.\n\nAnd the problem is more complex when you consider the massive amounts of real time data, the complex chemical \ninteractions and the most sophisticated and expensive equipment. Generic big data firms just don't get it for this \nindustry, but there is another way.\n\nAspen Tech is breaking new ground by combining cutting edge data science with the most sophisticated process \nmodeling technology. With 35 years of trusted experience, Aspen Tech introduces Aspen Asset Analytics, the first \nand only solution for the process industry that leverages models they already have, can be rapidly deployed, is self \ncalibrating, and self maintaining.\n\nOur analytics combines models, historical data, and data analytics to predict unplanned events before they happen \nand prescribe corrective action. Pattern discovery takes large datasets and identify similar events in a timeline. Root \ncause analysis uses these similar events to predict future events so operators can make better decisions.\n\nAspen Asset Analytics is a major step in moving beyond process optimization towards asset optimization. \nCompanies in the process industry can save billions of dollars every year and that's just the beginning. Aspen \nAsset Analytics.\n\n\n\n[Video Ends]\n\nJOSH FREDBERG: So with that I'm going to conclude. Thank you for your time and I'm going to pass the baton to \nKarl.\n\nKARL JOHNSEN, SVP OF FINANCE, CFO, ASPEN TECHNOLOGY: All right. Thank you Josh. I forgot my \nglasses. Okay. All right. Thank you. Good afternoon everyone. So today I'm going to be walking us through the \nfinancial model for Aspen Tech, go over some of the Q3 year-to-date results and then we'll wrap it off with going \nover our preliminary view of fiscal year '17 guidance.\n\nSo as Antonio mentioned earlier, Aspen Tech has a multibillion dollar market opportunity. We have a proven track \nrecord of being able to grow into that market while maintaining our profitability and cash flow metrics which are best \nin class in the industry, which result in our strong balance sheet and income statement and cash flows which \nultimately fund our capital allocation strategy.\n\nOur focus is to drive shareholder value through growing organically and inorganically and when applicable and \nwhen accretive, returning capital back to our shareholders. Excuse me.\n\nSo when we start to look at the financial model for Aspen Tech, we start with the annual spend. So annual spend is \na metric that we have that gives insight into our customers' base growth and into the churn of the health of that \nbase and also as a leading indicator of our revenue.\n\nFor those that are new to the story for Aspen Tech, annual spend is simply the aggregation of all our current \ninvoices for our subscription term maintenance and license agreement. Ultimately, it's a proxy for our annualized \nsubscription revenue at any point in time.\n\nThe real strength of our annual spend comes from the underlying customer contracts. Our contracts have a five to \nsix year term, have 2% to 3% price escalation on an annual basis and are non-cancellable.\n\nCustomers can add additional entitlement during the period or if they were to add additional entitlement, they're \nunable to cancel that before the end of the term. As you can see, historically our growth rate in the annual spend \nhas been in the low double digits. In fiscal year '16, the oil prices had an adverse impact on a couple of our market, \nspecifically the E&C and the upstream but we still expect to have 3% to 6% growth in annual spend that's really \nrelated to the strength of our downstream and our chemical verticals.\n\nAnd before we leave this slide, I just want to remind everybody, I get questioned a lot of how does annual spend \nturn into revenue? And we recognize revenue on subscription basis so what really means is if you grow annual \nspend in one period, it really isn't reflected until the subsequent quarter into revenue or on the balance sheet. So \nreally starts when we invoice the customer.\n\nSo to really understand annual spend, you have to understand how it grows and to understand how it grows we \nbreak it into its components. So annual spend starts with the beginning annual spend which is really the contractual \nbase that you have exiting the prior period. And as I mentioned, we have 2% to 3% escalation every year.\n\nSo that annual spend will grow 2% to 3% right through the year, doesn't come in at the beginning but will grow over \nthe year just through that price escalation. The largest contributor that we have to our growth is new entitlement or \nnew spend. Now our customers really do this in two different ways, the first on renewals, customers will reevaluate \ntheir need, they'll look at volume discounts, and they usually will then adjust their spend.\n\nAlso and just equally important is the customers will during the contract term add additional entitlement, and we've \ntraditionally seen this being, well, a lot of growth in both of these and we continue to see that even in this market.\n\nThe third contributor to growth and it's a much smaller contributor is new logos. Typically this comes from our S&B \ngroup which is the equivalent of our inside sales. So think of small, medium businesses, these are smaller \nengineering companies that we sell into. But again, it's a much smaller piece of it.\n\n\n\nAnd when we look at these three pieces together, this is what we refer to as gross growth. So a bit of a mouthful \nsometimes when we say it, but we're looking at this is where the growth comes from in annual spend.\n\nNow going against that is a new term we're using which is attrition. So again, I'll dive into this in a moment, we've \ntypically talked about nonrenewal rates. When you think of this, think of it as the percentage of annual spend that \nwas up for renewal in a period that didn't renew. And again, it may not renew meaning customer renewed with \nlower entitlement or they didn't renew at all.\n\nTake that as a percentage of your beginning annual spend. And as we look at these four components, this is the net \ngrowth that we report. So when we report annual spend growth, these are the different components. And you just \ntake it across to get to your annual spend.\n\nSo as I mentioned earlier, we're starting to look at the renewal rates differently. And again, it will approximate each \nother. Historically, we've given renewal rates based on our TLCV metric which we used during the conversion from \nour old commercial model to a new subscription model and it's been based on that.\n\nBecause we look at annual spend for growth, we're going to start providing information on renewals based on \nannual spend. And again, you can see they approximate each other, they're not that different but again, just to have \na consistent base of information that we're working off of, we're going to work off of annual spend.\n\nSo again, you go through how do we define it, attrition? A customer comes up for renewal, they renew a portion of \ntheir previous entitlement or they don't renew, that aggregate amount will go against our beginning annual spend.\n\nAn important note for this is also, if a customer were not to renew in a quarter, say renewed late but then they \nrenewed in a subsequent quarter, they would still be in the attrition rate, we would not retroactively adjust the \nattrition rates. So we get attrition rates at a point in time that are cumulative and that customer would still be in \nthere for the full year's attrition rate.\n\nCurrently right now we're running about 5% and that's year-to-date Q3, so we still have another quarter of activity \nthat could influence that up a little bit, and you can see that compares to our year-to-date TLCV of about 4% to 5%.\n\nSo again, the takeaways from here, it's not that much of a different metric from what we've provided before, it's \nbased on the same metrics that we're giving to you for growth so now it can be comparable. And lastly, we'll be \nproviding this on an annual basis.\n\nSo the other area I get a good number of questions is deferred revenue, and how does it grow and why is it a little \nbit of inconsistency between quarters. So when you think of annual spend, it will grow in accordance with - I mean \nwhen you think of deferred revenue, it grows in accordance to the annual spend but it trails it.\n\nSo annual spend will come in one quarter, the reflection of that predominantly will be on the balance sheet the \nsubsequent quarter. So they'll trail it a little bit and then you'll get a lot of volatility between quarters and that's really \nrelated to our nonlinear invoicing.\n\nSo as you can see, Q1 and Q2 are our lowest invoicing periods and these are our fiscal quarters and then Q3 is the \nhighest and then Q4 is a little bit down in the middle. And what's interesting to note is that in Q1 and Q2 your \ninvoicing is below your revenue. So you're going to see a decrease in deferred revenue.\n\nAnd the reason a lot of these questions come up is until this year, until fiscal year '16 we were in the middle of a \ntransition so it wasn't a meaningful metric. So we couldn't compare between years and now you can.\n\nAnd just one last point on the deferred revenue, when you go comparing fiscal year '16 to fiscal year '15, one of the \npoints you have to remember is that in '15 we had about $10 million of deferred revenue that wasn't recognized on \nsubscription basis in '16. So in '16, we have about $10 million of revenue that we've talked about in our earnings \ncalls that was in deferred revenue in '15 that came in as sort of a lump sum, it didn't come ratably and additionally \nwas not replaced. So we don't have that anymore. So when you adjust '15 for that anomaly, you'll see that '15 and \n'16 the growth rates really start making sense when you compare them to annual spend.\n\n\n\nSo I shift into our profitability and our expense metrics. This is our current view of our target operating model and \nthis is where we see the optimum level between investment and profitability.\n\nAnd when you think of those investments, that's the fund the items that Josh talked about, funding our \ninfrastructure, corporate infrastructure and this is consistent with last year and an R&D about 14% to 15%.\n\nIf we were to grow a little bit more rapidly, so if you were to see an uptick in the revenue, there is additional \nleverage in this model, it isn't linear, you wouldn't see that move directly with revenue so you would expect to see a \nlittle bit more leverage coming out of that model.\n\nSo comparing our Q3 results to our target values, you can see that for GAAP and non-GAAP operating margins, we \nwell exceeded both of those. But you really need to look at fiscal year '16 and adjust it a little bit for a couple of \nitems. So we had that $10 million of revenue that I talked about earlier, so that artificially brought up '16.\n\nIn addition, we're running behind where we forecasted annual spend so your commission rates are running a little \nbit behind where they normally would be. So when you adjust for both of those, you start coming back into what our \ntarget values would be. So '16 a little bit inflated and lastly you also have to adjust a little bit of '16 which is hard to \nget the numbers for you but KVC, when we started bidding on KVC, we slowed down our internal investments and \nspend and hiring in anticipation of that acquisition.\n\nOnce we decided not to continue the bid for KVC in Q3 and Q4, we then continued that investment and started \nramping it up which you could see was in our Q3 actuals and our Q4 guidance.\n\nSo this is a good slide to show where the leverage and our models come. So for the past five years we've been \nable to grow revenue steadily on consistent expenses. As you can see in '16's guidance, it's a little bit of a tick up \nover '15. And if you were able to break and take a look at just what we were saying for Q3 and then our guidance \nfor Q4, you'd see that a lot of that is a little bit lopsided toward there. So your exit rate is a little bit higher.\n\nSo as you enter '17, you get a slightly higher expense rate and that really reflect some of those investments that \nwe've been talking about both in R&D, marketing, and then also the corporate infrastructure.\n\nAnd both of those lead to our cash flow. So our cash flow is truly one of the most predictable, strong metrics that we \nhave. As you can see in '16, we became a cash tax payer and that we're anticipating about $65 million to $70 \nmillion of taxes being paid in cash in '16.\n\nIf you were to adjust our '16 guidance and then look at '15 to take it down for the nonrecurring receipts we talked \nabout in Q4 of '15, you'd see that that growth rate would be approximate that 3% to 4% that you would have \nexpected.\n\nSo that leads us to our capital allocation. So we talk a lot about our capital allocation. We have a very disciplined, \nmethodical approach to our capital allocation. We typically look first to M&A and that's really because we see M&A \nbeing accretive on the long-term for our shareholders over other options.\n\nBut again, still as Antonio alluded to earlier, any M&A opportunity is evaluated both on financial and strategic basis. \nSo we have certain targets that meet the financial but they may not meet strategic and vice versa. KVC was one of \nthe first ones that met both until the point that hit an inflection point when Yokagama came in and upped the bid, it \ncrossed a threshold where it was no longer from a financial point of view accretive to the business.\n\nWhen that happened, it's a great example of the discipline that we apply to our capital allocation is we reevaluated \nthe opportunity, looked to returning worth to shareholders and it was more accretive to return that capital to \nshareholders than it would have been to keep pursuing KVC.\n\nLooking at our target capital structure, we see having approximately $100 million of cash on hand combined with a \nhalf turn or two turns of leverage being the optimal for us. That $100 million of cash, it's not a defensive position but \nit's more to allow us to be very nimble and aggressive as we see opportunities, strategic opportunities arise.\n\n\n\nWe also have leverage - we have capacity under our line of credit for about $110 million that will allow us to \ncombine to that quickly on any M&A opportunities. We've recently put on the leverage for first time in a little while in \nthis company's history so we have about $150 million are just under half a turn of leverage and we have about $250 \nmillion of total capacity of the line.\n\nWe would see going up to three to four turns of EBITDA for a strategic opportunity but then coming back down \nafterwards as we integrate whatever the opportunity might be.\n\nSo historically you can see how we've been allocating our capital and you could see it's very heavily weighted \ntoward returning capital to shareholders, and we do that when we see that disconnect between the intrinsic value of \nthe company and what the market is valuing us.\n\nWhen we see a disconnect and we see an opportunity, we deploy capital to take advantage of that opportunity. In \ngeneral, this is a reflection of that opportunity being there, deploying capital against it, but even more so the \nopportunities that we have in M&A, we do review them but again we haven't had any larger ones that meet the \ncriteria that we've been looking for.\n\nAnd the amounts you do see for acquisitions are really related to some small tuck-in acquisitions. So the impact that \nthis has had over time on our shares is we bought back at the end of Q3 roughly what, $616 million worth of shares \nand that's reduced our outstanding shares by about 12%.\n\nAnd that 12% is roughly about - it's 12% but it includes, it's a net number so it includes the impact of the additional \nshares that we've been issuing under equity plans, so the 12% is a net number. You can see it's had a significant \nimpact on our outstanding shares.\n\nSo turning to guidance, so a couple points before we dive into guidance. For fiscal year '16, we're not changing our \nview so we're going to maintain the view that we shared during Q3. And again, this is our preliminary guidance \nbased on where we are today. So we're a little bit out from the start of '17, this is where stand today.\n\nSo I'll start with annual spend. So we're guiding today for about 3% to 6% of annual spend growth next year and \nreally the assumptions that are related to this are that we're assuming the current market conditions that we're \nexperiencing today will carry forward to next year.\n\nWe're seeing that the increase in oil prices that we've just seen since February really aren't going to have material \nimpact on the buying behaviors of our customers as they're going to start their budgeting process come the \nSeptember-October timeframe and that will take some time to work its way down to us.\n\nAnd lastly, we're assuming that we'll have either flat or slightly down attrition rates. So we're going to assume that \nwe're going to have roughly the same to slightly down attrition next year.\n\nUNIDENTIFIED AUDIENCE MEMBER: And when you say down, in other words five or worse? Five or worse \nversus two to three attrition?\n\nKARL JOHNSEN: So five or better. So going to how that translates into revenue for next year, so we'll be seeing \n470 to 477 of total revenue.\n\nAnd when you look at this, it's important to look at fiscal year '16, you need to pull out the $10 million of \nnonrecurring revenue that was in there because again, that wasn't part of our subscription base, it was a revenue \nthat got hung up and was delivered in prior periods but due to accounting rules we had to hold on to it.\n\nSo when you look at that and you adjust '17, you'll see that you'll have about a 4% growth in your subscription base \nand about 10% reduction of professional services. And what that's reflecting, the down in professional services is \nreally reflecting the discretionary spend that's being cut at our end customers, training, discretionary professional \nservice projects.\n\n\n\nAnd again, some other important points to remember is in '17 we don't have any more one time revenues hung up \non the balance sheet so we won't expect to have any more onetime items coming in. And lastly, the revenue will \nfluctuate depending on how annual spend comes in. So we have a view on how it's going to come in but if it were to \nchange that could impact us.\n\nWhen we look at fiscal year '17 expense guidance, again you have to look at the '16 and right size it for a couple of \nthose items that I talked about earlier. But in general, this is reflecting our investment in R&D and in the corporate IT \ninfrastructure, and to a lesser extent some of our digital marketing.\n\nAnd we're making these investment now because unlike a lot of our competitors in other companies, the strength of \nour financial model, the strength of our customer contracts, the cash flow, they allow us to make these investments \nnow so that when this market turns around and we start seeing higher oil price, and so the spend starts coming \nback we'll be well positioned to take advantage of it.\n\nSo this leaves us to free cash flow. So again, we're expecting $65 million to $70 million of free cash flow of cash \ntaxes next year and about $160 million to $165 million of free cash flow.\n\nAnd again, in that number, it equates roughly about 2% to 3% growth year-over-year and in that number includes \nabout $3 million to $4 million of interest expense that we're leaving in and we're not pro-forma-ing out the expense.\n\nUNIDENTIFIED AUDIENCE MEMBER: That's flat share year-over-year?\n\nKARL JOHNSEN: Yes.\n\nUNIDENTIFIED AUDIENCE MEMBER: Per share basis?\n\nKARL JOHNSEN: So we're keeping that. We have not taken out the impact of the $400 million.\n\nSo in summary, we're looking at about a 46% to 40% Non-GAAP operating margin which again slightly down from \nlast year but again, we're taking advantage of the opportunity to invest in R&D and our corporate infrastructure.\n\nIt doesn't include onetime revenue items, it doesn't reflect any potential acquisitions that we may close in the year, \nand lastly the $400 million of share repurchases are not reflected in the guidance for shares.\n\nI'll give everybody a moment to write down. Correct. Okay. So everybody, I'm going to move on to the closing. So in \nsummary, due to the strength of our financial model, the customer contracts, we're making investment today that in \na lot of ways represented by what Josh explained to us earlier, in the products, in the development such that we \ncan take advantage of that multibillion dollar market opportunity in the future.\n\nThis is all done with again a strong shareholder value increase focus for us and again we're relying on that financial \nmodel that's been built up over the last five to six years.\n\nSo with that, I'll invite Antonio and Josh back up to do Q&A.\n\n+++ Q&A\n\nANTONIO PIETRI: All right. Thank you Karla and thank you to the Aspen Tech team for the last four hours.\n\nHopefully you've got a better idea about the company, our strategy, our product direction, how we think about our \nproducts and how we think about running the company from a financial standpoint in '17.\n\nSo now it's time for questions. [Monica].\n\nUNIDENTIFIED PARTICIPANT: (inaudible microphone inaccessible)\n\n\n\nANTONIO PIETRI: Yes. [Monica], from our standpoint - so [Monica] is asking just so that the audience on the \nwebcast understands the question. [Monica] is asking whether - what are the assumptions we have put in to our \nguidance, annual spend guidance?\n\nWell basically we feel that we're in the middle of the adjustment that's going on in the industry. Yes, oil prices have \nmoved up to $45-$50 a barrel, but that's only in the last month.\n\nTime will tell whether they're going to stay up there and time will tell what customers would budget for '17 so we felt \nthat the conservative assumption and the right assumption was to assume that things will remain the same and \nwe'll see how the fiscal year develops as we get into it.\n\nUNIDENTIFIED PARTICIPANT: In the annual update of the last earnings call, you talked about (inaudible \nmicrophone inaccessible)\n\nANTONIO PIETRI: Uh-hmm. Yes. We said in our earnings call for Q3 that we are working on these three NOC \ncontracts and we had some sizeable transactions in the pipeline for Q4.\n\nWe're a month from the end of the quarter, we continue to work all those deals and during the earnings call for Q4 \nwe'll tell you what happened. We'll tell you what happen in our earnings call for Q4.\n\nUNIDENTIFIED PARTICIPANT: So when you look at the fiscal '17 guidance, since you give us kind of the heads up \nabout the NOCs for this year, what should we expect in terms of what that rule pipeline looks like next year so we \ncan apply the - you know, the attrition rate, the 5% of that (inaudible microphone inaccessible)\n\nANTONIO PIETRI: Well certainly these three contracts that did not renew contributed materially to the attrition rate \nin '16.\n\nI also said in our Q1 earnings call in October that we had a unique situation this year, we had an accumulation \nconcentration of these NOCs renewals this year. That does not exist to the extent that it did in '16.\n\nSo we are assuming though that we'll have outside of those type of renewals we'll have a similar attrition rate just \nbecause we haven't seen a change in the condition and that's the assumption that we have in our guidance.\n\nUNIDENTIFIED PARTICIPANT: Could you frame the opportunity for the new (inaudible microphone inaccessible) \nyou talked about maintenance optimization and analytics, you know, if you have a customer spending $100 of \nannual spend with you.\n\nAnd they take on both of their products kind of as you would hope, where does that $100 go to? Does it go to the \n$120, does it go to $130? Just help us frame how material they are in terms of moving the needle.\n\nANTONIO PIETRI: Well look, as you should have mentioned, just on this initial release for analytics and the focus \non columns, by the way the 100,000 columns is on the chemicals market alone, it doesn't include refining.\n\nWe haven't priced analytics offering yet but you can consider that it's material to our existing TAM, okay? And the \nother thing is that we also believe that these are separate budgets from where customers fund our technology \ntoday. [Stanley]?\n\nUNIDENTIFIED PARTICIPANT: So if you look at the - earlier in the presentation you looked at the massive amount \nof savings or activity that you give your customers. Obviously right now is probably a hard time to think about \npricing but it would seem like there's such a massive disconnect between the value that we're giving them and what \nyou're charging.\n\nYou know, is there an opportunity to revisit that, to think about gain share type of pricing and other things moving \nforward?\n\n\n\nANTONIO PIETRI: Well look, I think the introduction of asset maintenance and the aspenOne maintenance and \nanalytics suite is an opportunity to price the new solution at fresh price points and token values for the new solution.\n\nEven though it's going to leverage existing products, the products that are required to run those solutions will go \ninto that suite as well and will allow us to sort of start afresh with a new suite and a new space.\n\nAnd you're right, when you look at the value that we generate is sometimes a 100 to 1, can we get more for what w \ndeliver? We always try but, you know, there are constraints that we push against.\n\nUNIDENTIFIED PARTICIPANT: We'll be flipping around the other way, we look at the, you know, the weight space \nas you outlined in the (inaudible microphone inaccessible) for the last couple of years and think about or talk about \nhow you drive the penetration.\n\nIt seems like the way that you're driving penetration like be shifting again to more of a top - you know, get higher in \nthe organization and try to get more of a mandate across the business. You know, how should we think about how \nlong maybe it takes to get some of that traction so maybe we can see more penetration of that?\n\nANTONIO PIETRI: You heard when we announced the KVC acquisition that one of the rationales for it was that C-\nlevel mindshare that KVC had.\n\nWith Bill Griffin coming into the company, we've put a greater emphasis on engaging at a higher level with our \ncustomers. Bill is leading that initiative and eventually we believe it will start paying off for us.\n\nHow long it will take? We'll see but we're confident on that. The one thing about Aspen Tech that I'll mention, you \nknow, Aspen Tech of course in the context of the Oracles and maybe even the Salesforces of the world, the \nMicrosoft is a small company but the fact is that we have tremendous access to C-level executives as well and it is \nnot a hard work to get in there and talk to them about broader deployments of our software. So we're confident that \nwe can get that traction. Go ahead, yes.\n\nUNIDENTIFIED PARTICIPANT: Yes. On the maintenance said that you mentioned is very fragmented space, \nthere's (inaudible microphone inaccessible) are these companies you could potentially rollup or are they part of a \nlarger organization?\n\nAnd also in terms of how you plan as part of the maintenance department, is it primarily green space or more \ndisplace some of these practices (inaudible microphone inaccessible)\n\nANTONIO PIETRI: Well look, it is a fragmented space. There's multiple player, some small and some, token small \nand perhaps you could qualify one of them as medium size.\n\nI just like to remind people when Aspen Tech consolidated this advance automation space and operations, it took \neight years to acquire 23 companies. This isn't going to happen overnight, this will take probably multiple years to \nconsolidate the space if that's what you want to call it.\n\nBut we do think it's going to require multiple acquisitions and organic development in our part as well as leveraging \nwhat we have on the design and operation space. [Monica]?\n\nUNIDENTIFIED PARTICIPANT: Just as a follow-up with that, also with the predictive (inaudible microphone \ninaccessible)\n\nJOSH FREDBERG: Yes. We're running a lighthouse program now. So what that means is the software \ncommercially meets our requirement, it's quality but we picked a dozen or so leading accounts.\n\nEvery one that we approached wanted to work with us and we were oversubscribed. And so they're actually putting \nthis technology into production and we're trying to collect the data and the results so that when we launch the \nproduct, not only can we talk about the technology but we can actually talk about the value that's delivered.\n\n\n\nUNIDENTIFIED PARTICIPANT: Then you've talked about (inaudible microphone inaccessible)\n\nANTONIO PIETRI: Soon. Yes.\n\nUNIDENTIFIED PARTICIPANT: Just on that, I think you had a slide that said if you adopted analytics with these \ntokens, is that...\n\nJOSH FREDBERG: That's a visualization layer on top of NBS. That's not the same thing as the maintenance and \nanalytics product suite. So we're going to probably have to rename that so that there's no confusion.\n\nUNIDENTIFIED PARTICIPANT: Is there any I guess risk that you layer on a third party (inaudible microphone \ninaccessible) to achieve some or all of what you're going to be developing? Versus what you're developing or is it \nimpossible to do that?\n\nJOSH FREDBERG: I wouldn't say. I mean, [Monica] you also asked about is this new, is it competitive?\n\nWe haven't found anybody that's actually focused on a process industry using models and data science to predict \noutcomes. There are firms that are trying to use data to reach conclusions but we haven't found anybody that's \ndoing that successfully in these kinds of problems. So it's all new and it isn't something that a generic BI tool is \ngoing to be able to do. It's much more than that. The math involved is very sophisticated and it's our crown jewels of \nthe company.\n\nANTONIO PIETRI: Yes?\n\nUNIDENTIFIED PARTICIPANT: A couple of (inaudible microphone inaccessible) in R&D resource that are going to \nbe necessary to support this rollout, you know, are you going to need (inaudible microphone inaccessible) that is \nalready doing it?\n\nANTONIO PIETRI: Well I'll answer the second part of the question first. You know, we've been working on this for \n18 months solid with a sizeable team.\n\nSo that expense is baked into R&D expense. Will it go up in the future? Perhaps but I don't think it's going to require \ntens of millions of dollars of additional investment. Look, it's the same customers. It's the same customers, it's \nperhaps in some cases a different department, the maintenance department in those refineries as opposed to the \nprocess engineering department or the control department and I believe that our sales account teams will be able to \nmanage those accounts with the same headcount.\n\nWill require some additional headcount from a technical sale support? Perhaps. You know, as we grow the \nopportunity, I can see as a staff as we see the opportunity grow.\n\nUNIDENTIFIED PARTICIPANT: This year and next year when you talk about (inaudible microphone inaccessible) \nof this year. Does that mean that it's not this year they're going to be (inaudible microphone inaccessible)\n\nANTONIO PIETRI: Yes. Well look, we'll see what happens with the NOCs and where they will be whether they'll be \nin this year, next year. We'd assume some things about next fiscal year, again, the attrition rate, what we're seeing \nin the business. The NOCs whether they are full renewals or partial renewals of what expired, time will tell as well. \nYes [Stanley].\n\nUNIDENTIFIED PARTICIPANT: When you guys showed the attrition rate, are you measuring that by customer \nattrition or token attrition?\n\nKARL JOHNSEN: It's by dollar attrition. So we'll tell you again. So it's the dollar amount of the annual spend that's \nup for renewal and then whatever doesn't renew, that's the amount that we'll aggregate.\n\nUNIDENTIFIED PARTICIPANT: That way you'll capture the - because I can't imagine a customer goes away.\n\n\n\nKARL JOHNSEN: Yes, they go - they trick down the - yes. So they'll be comparable to annual spend because \nannual spend is based on dollars, the attrition will be based on dollars.\n\nANTONIO PIETRI: Yes. I think Karl and the team did a very good job coming up with a metric on attrition that is tied \nto annual spend which is a metric that were given you guys.\n\nYes, go ahead.\n\nUNIDENTIFIED PARTICIPANT: What was that historical attrition rate on annual spend? Can you give a historical \nyear-to-date on TLCV and it would be the year-to-date attrition, the annual spend historical.\n\nKARL JOHNSEN: Yes. So it's a new metric for us. So we did go back and look at it, it's in that 3% to 4% range. So \nagain, it seems to be tracking just to the mechanics of the math of annual spend versus TLCV about half a point to \na full point above.\n\nANTONIO PIETRI: Yes.\n\nUNIDENTIFIED PARTICIPANT: Two questions, one just in terms of activity, how are you thinking about it now with \nthe trends, what does look like? And then two is more on the (inaudible)\n\nANTONIO PIETRI: Let me answer the first question. Look, of course in this environment the sales productivity, I \nused to think that - well and I believe we had done an excellent job driving the sale productivity per sales account \nperson significantly up.\n\nOf course in this environment that's come down through the floor. We need to get back and then as the business \ngrows rebuild the sales productivity and that's part of what we're focusing on. I do think there's been an opportunity \nover the last six months to look at especially the SMB organization because that's an organization that grew very \nrapidly as a business crew over the last three years but it's also an organization that got hit first nine months ago.\n\nSo we've looked at that and as part of the job that Bill is doing on making sure that we had the right investments in \nthe right regions and groups to drive growth in the future.\n\nKARL JOHNSEN: So on the new revenue standard, on 606 we're still evaluating what the impact will be on us. \nWe'll start developing a view on that as we - in the next couple of months to quarters and we'll probably in '17 start \ngiving some initial thoughts on where I think it's going to be.\n\nAnd it really just started finalizing it so there's a couple of open pieces now that's really settled down and starting to \nget agreement on the last open items, we'll start a process of analyzing the impact. But for us we'll adopt it for fiscal \nyear '19 so we'll be adopting it 7/ 1/2018.\n\nANTONIO PIETRI: Yes.\n\nUNIDENTIFIED PARTICIPANT: The 2% annual escalator that's contractual, so you have visibility into that \n(inaudible) for large customers, how much visibility do you have that special services being done is the right \nnumber?\n\nANTONIO PIETRI: Well I mean look, we do a forecasting exercise at the beginning of every calendar of January, \nFebruary timeframe and we look at really two and a half years ahead but this time we really put the emphasis a \nyear and a half ahead.\n\nWe'll deliver certain performance in fiscal year '16 for professional services while we're projecting for professional \nservices in '17, bakes in underperformance and bookings in that area and therefore the revenue has slowed down.\n\nUNIDENTIFIED PARTICIPANT: To execute the $400 million buyback, was that due from cash on balance sheet \nplus (inaudible microphone inaccessible) or do you take on additional debt?\n\nKARL JOHNSEN: So that's going to be the cash on hand plus what we generate in fiscal year '17.\n\n\n\nANTONIO PIETRI: Yes?\n\nUNIDENTIFIED PARTICIPANT: Did you guys track promoter scores internally?\n\nANTONIO PIETRI: Yes, no. Look, I think part of our engagement with customers is focused on making sure that \nwe're better attuned to our relationships with our customers both on the product innovation side where customers \nfelt we were a little distant from them over the last few years.\n\nThat's one of the big changes that Josh has driven in the last 18 months, it just get a lot closer t our customers on \nproduct innovation and we're seeing the feedback and increased enthusiasm from customers in that area.\n\nOn our sales relationships and customer support relationships, we are working also on improving those \nrelationships from beyond what they are today and there's always room to improve our net promoters scores and \nthat's something that we're always working on.\n\nIt's an area that I'm emphasizing to the organization just because I believe that the better your customer \nrelationships the better it is easier to do business and the more appreciative they are of what you do so. Yes.\n\nUNIDENTIFIED PARTICIPANT: In terms of the competition that you're ability to sort (inaudible microphone \ninaccessible) at all or I guess know the way (inaudible microphone inaccessible)\n\nANTONIO PIETRI: Well I mean look, in extreme environments you see sometimes irrational behavior and I think \nwe've seen that from some customers and also from competitors.\n\nI think time will tell what the outcome of these downturn and competitors. We've heard through the market that one \nof our competitors closed part of their operations in the region and moved them to another region, but I do think that \nthere's no doubt that through the work we're doing in our products and the increased focus that we're driving with \nour customers we're going to extend that lead on them. But we're in the middle of the maelstrom at the moment. \nYes.\n\nUNIDENTIFIED PARTICIPANT: On the balance sheet, what is the (inaudible microphone inaccessible)\n\nKARL JOHNSEN: Well right now we're in a revolver just because we're anticipating do we want to kind of like bring \nit up or bring it back down to it fits our needs now. If we thought we're going to have permanent debt on there then, \nyes, we would take a different view into different instruments. Is that your question is do we have more long-term \ndebt?\n\nUNIDENTIFIED PARTICIPANT: Yes. But (inaudible microphone inaccessible) balance sheet?\n\nKARL JOHNSEN: Yes. We have to bring it on for a reason though and that's one of the things because as you saw, \nthere's not a large M&A opportunity out there. If there was, that would be the mechanism to start bringing it up.\n\nAt least in fiscal '17, maybe beyond that that position could change. But right now we're planning on buying back \nabout $400 million in '17. So levering up to buy back, you know, additional amounts probably isn't the right answer. \nIf the right acquisition came around, we need to lever up, we may use the revolver to execute it and then shift it over \nto a more long-term.\n\nUNIDENTIFIED AUDIENCE MEMBER: Can you provide some more specifics on the investments of China? Are \nyou opening up any facilities?\n\nANTONIO PIETRI: Well I mean I won't give you specifics on headcount but what I'll tell you though 10 years ago \nthe private chemical industry in China was about 10% of the total chemical industry.\n\nToday it's 53% of the total chemical industry and the chemical industry in China is multiple times of what it was 10 \nyears ago. We believe there's a significant opportunity in China for us to move more aggressively into the \nchemical's market and that's really a sales headcount investment and probably customer support at some point.\n\n\n\nWe have already made in FY16 an investment in that regard, you know, that growth lags investment but as we see \nthe growth we'll continue to invest in China. I actually think that is a significant under-tapped opportunity for us, \nChina.\n\nUNIDENTIFIED PARTICIPANT: It's more of a (inaudible microphone inaccessible)\n\nANTONIO PIETRI: Yes. I think methodical. I mean we want to make sure that we've made an investment already, \nwe want to see that return and then continue to invest after that.\n\nBut I - we've been in China since 1983, we've been very focused on a segment of that market. We've been - we've \ndone very well there. Some of our largest customers are in China as a matter of fact but there's still a significant \nopportunity there for us. So, yes.\n\nUNIDENTIFIED PARTICIPANT: Just specifically in the product level. So the MSC suite, is that (inaudible \nmicrophone inaccessible) experience? And then comparing the two products, the retention rates...\n\nANTONIO PIETRI: Yes. That's right. Yes to everything there. Yes.\n\nUNIDENTIFIED PARTICIPANT: I'll just ask on the balance sheet (inaudible microphone inaccessible) is really \nhigher than that. But why wait for a transaction or something?\n\nANTONIO PIETRI: But I mean I think it's more a philosophical sort of point of view from our standpoint. You know, \nwe saw an opportunity to announce that $400 million share buyback for next year considering that we had taken on \nalready a certain amount of debt as part of the KVC acquisition.\n\nTaking on debt for the sake of debt is not something that we've considered in the past unless we saw a significant \ndislocation between our share price and what we thought they were valued. So it's not something that we'd \nconsider. Just we've had a lot of offers from different sources to really lever up the balance sheet and it's just not \nsomething that we consider.\n\nUNIDENTIFIED PARTICIPANT: Folks want to lend you money?\n\nANTONIO PIETRI: There's people willing to lend money out there. Yes.\n\nUNIDENTIFIED AUDIENCE MEMBER: Just play devil's advocate, you started last year with an annual customer \nspend growth rate that kind of came down through the year.\n\nI mean given the preliminary guidance that's kind of in line with what you're experiencing currently, why didn't you \ntake, you know, the opportunity to just take it down a step and, you know, kind of kitchen sink in so people feel like, \nyou know, what, yes, feels like the worst is behind us and this is the number that you can come back and, you \nknow, people raise on the annual customer spend. What is it about the pipeline or something else that using the \nconfidence that this is the number to work off of?\n\nANTONIO PIETRI: Well I mean look, like I said human psychology, it's interesting and I'm not going to do a course \non human psychology here but at this time last year we were in line for a double digit growth year and all the \nprojections show that.\n\nWe've done our sales projections for the next year and a half, two years and human psychology would detect that, \nyou know, you tend to be much more conservative in that case because of the environment that you're in. We \nlooked at the pipeline, we scrubbed it, upside down and sideways and we concluded that three to six is the range \nthat we can deliver for in '17. Yes.\n\nUNIDENTIFIED PARTICIPANT: Can I just ask you a question? So you talked a little bit about making (inaudible \nmicrophone inaccessible) services proactive, problems being detected. You also addressed the prospect of \nperhaps providing invites to your customer.\n\n\n\nIf you weighed the consequences of providing advice that's based on a model turn out to be inaccurate, how does \nthat play to your thought process of looking forward in (inaudible microphone inaccessible)?\n\nJOSH FREDBERG: You want to take this or should I?\n\nANTONIO PIETRI: Well you can give a try and then I'll follow.\n\nJOSH FREDBERG: Customers are using models today to answer questions. They're using them in engineering; \nthey're using engineering models in operations.\n\nIt's no different really than using our technology the way they view start technology in the past. The liability for a \nsoftware company to provide an answer and what's done with that answer, I don't believe the liability is with us.\n\nBut we do try to provide confidence, confidence intervals so that we know - you know, when you saw the actual \nscreen that said there's something going to happen and then had probabilities involved, so try to provide that kind of \nconfidence interval so that as much information can we provide and what actions are taken and whether there'd be \nan action and then the company would be liable, I don't think that's within our contracts, I don't think that's a liability \nfor us.\n\nUNIDENTIFIED PARTICIPANT: But that's really the fundamental question is between your contract that whatever \nsuggestion your software comes up with about running the operation or parts need to be replaced.\n\nJOSH FREDBERG: Yes. Ultimately the decisions that are made, the responsibility of the company, so whether \nthey're using our software to design a plant, whether using our software to make an operating decision, it's the \nsame. Ultimately the operator has the role to make the right decision.\n\nANTONIO PIETRI: I think Josh has put on - at the end of the day those recommendations, those prescriptive \nactions are in the context of either an engineer or an operator looking at them and judging them in the context of \ntheir experience operating that asset. And having been an applications engineer, implementing advance control, \nwhat you see is operators and engineers testing out whatever recommendations come out of software to make sure \nthat they're valid and building the confidence that eventually leads to more regular use of software.\n\nSo it's not blind faith if you will and it's very contextual as well based on the experience of those users. We probably \nhave time for one more question if there's any. Yes.\n\nUNIDENTIFIED PARTICIPANT: It's (inaudible microphone inaccessible) how about the KVC - how about kind of \nwhat are the things that (inaudible microphone inaccessible)\n\nANTONIO PIETRI: Well I mean look, it's the current environment. Just plain - the current environment, there's \nhardly any spend on owner operators as leading to E&C work. E&Cs are still laying people off. We see the strength \nin the chemicals business, we still see the strength in the refining business, we see a very challenged upstream and \nmidstream business, E&C business.\n\nNow we're going to come here to the end of this yea. Will oil prices being at $50 a barrel for six months and that's \ncreated enough confidence in our customers to budget for higher dollars which would lead to better investment or \nbetter spending in calendar '17? If that's the case, well hopefully we'll see the benefit but it's only then in the second \nhalf of our fiscal years.\n\nSo, you know, at this point ,we don't see any reason to think that the environment is going to change. It may but I \nthink from a guidance standpoint, preliminary guidance standpoint we felt this was the right spot.\n\nOkay. Well I want to thank everyone for trekking to Bedford, Massachusetts and visiting our new corporate \nheadquarters. Hopefully this was useful and gives you better context for the company and we'll see you in the road. \nThank you all.\n\nKARL JOHNSEN: Thank you.\n\n\n\nANTONIO PIETRI: Thank you.\n\n[Thomson Financial reserves the right to make changes to documents, content, or other information on this web site \nwithout obligation to notify any person of such changes.\n\nIn the conference calls upon which Event Transcripts are based, companies may make projections or other forward-\nlooking statements regarding a variety of items. Such forward-looking statements are based upon current \nexpectations and involve risks and uncertainties. Actual results may differ materially from those stated in any \nforward-looking statement based on a number of important factors and risks, which are more specifically identified \nin the companies' most recent SEC filings. Although the companies may indicate and believe that the assumptions \nunderlying the forward-looking statements are reasonable, any of the assumptions could prove inaccurate or \nincorrect and, therefore, there can be no assurance that the results contemplated in the forward-looking statements \nwill be realized.\n\nTHE INFORMATION CONTAINED IN EVENT TRANSCRIPTS IS A TEXTUAL REPRESENTATION OF THE \nAPPLICABLE COMPANY'S CONFERENCE CALL AND WHILE EFFORTS ARE MADE TO PROVIDE AN \nACCURATE TRANSCRIPTION, THERE MAY BE MATERIAL ERRORS, OMISSIONS, OR INACCURACIES IN \nTHE REPORTING OF THE SUBSTANCE OF THE CONFERENCE CALLS. IN NO WAY DOES THOMSON \nFINANCIAL OR THE APPLICABLE COMPANY OR THE APPLICABLE COMPANY ASSUME ANY \nRESPONSIBILITY FOR ANY INVESTMENT OR OTHER DECISIONS MADE BASED UPON THE INFORMATION \nPROVIDED ON THIS WEB SITE OR IN ANY EVENT TRANSCRIPT. USERS ARE ADVISED TO REVIEW THE \nAPPLICABLE COMPANY'S CONFERENCE CALL ITSELF AND THE APPLICABLE COMPANY'S SEC FILINGS \nBEFORE MAKING ANY INVESTMENT OR OTHER DECISIONS.]\n"}